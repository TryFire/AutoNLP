{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AutoDL_ingestion_program.dataset import AutoNLPDataset\n",
    "import re\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.autograd as ag\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import jieba\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_en_text(dat):\n",
    "\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[\"/(){}\\[\\]\\|@,;]')\n",
    "    BAD_SYMBOLS_RE = re.compile('[^0-9a-zA-Z #+_]')\n",
    "\n",
    "    ret = []\n",
    "    for line in dat:\n",
    "        # text = text.lower() # lowercase text\n",
    "        line = REPLACE_BY_SPACE_RE.sub(' ', line)\n",
    "        line = BAD_SYMBOLS_RE.sub('', line)\n",
    "        line = line.strip()\n",
    "        ret.append(line)\n",
    "    return ret\n",
    "\n",
    "def clean_zh_text(dat):\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[“”【】/（）：！～「」、|，；。\"/(){}\\[\\]\\|@,\\.;]')\n",
    "\n",
    "    ret = []\n",
    "    for line in dat:\n",
    "        line = REPLACE_BY_SPACE_RE.sub(' ', line)\n",
    "        line = line.strip()\n",
    "        ret.append(line)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def _tokenize_chinese_words(text):\n",
    "    return ' '.join(jieba.cut(text, cut_all=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoDaset = AutoNLPDataset('offline_data/O1/O1.data')\n",
    "autoDaset.read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = autoDaset.get_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a stirring , funny and finally transporting re-imagining of beauty and the beast and 1930s horror films \\n', 'apparently reassembled from the cutting-room floor of any given daytime soap . \\n', \"they presume their audience wo n't sit still for a sociology lesson , however entertainingly presented , so they trot out the conventional science-fiction elements of bug-eyed monsters and futuristic women in skimpy clothes . \\n\", 'this is a visually stunning rumination on love , memory , history and the war between art and commerce . \\n', \"jonathan parker 's bartleby should have been the be-all-end-all of the modern-office anomie films . \\n\"]\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# take a look at the what the data look like\n",
    "print(x_data[:5])\n",
    "print(y_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes :  2\n"
     ]
    }
   ],
   "source": [
    "num_class = autoDaset.get_metadata()['class_num']\n",
    "print('number of classes : ', num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "\n",
    "- The data has many punctuations, we can replace it by space.\n",
    "\n",
    "- There is not valid set, so we will split the whole dataset into transet ans valid set to better generate the training and hyper-parameters.\n",
    "\n",
    "- Each observation is a sentence which is hard to translated into presentation, we will split it to tokens.\n",
    "\n",
    "- We will convert data to Pytorch tensors so they can be used in a neural network. To do that, you must first create a dictionnary that will map words to integers. Add to the dictionnary only words that are in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if autoDaset.get_metadata()['language'] == 'ZH':\n",
    "    x_data = clean_zh_text(x_data)\n",
    "    x_data = list(map(_tokenize_chinese_words, x_data))\n",
    "else:\n",
    "    x_data = clean_en_text(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of transet :  7792\n"
     ]
    }
   ],
   "source": [
    "print('number of transet : ', len(x_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'stirring',\n",
       " 'funny',\n",
       " 'and',\n",
       " 'finally',\n",
       " 'transporting',\n",
       " 'reimagining',\n",
       " 'of',\n",
       " 'beauty',\n",
       " 'and',\n",
       " 'the',\n",
       " 'beast',\n",
       " 'and',\n",
       " '1930s',\n",
       " 'horror',\n",
       " 'films']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = list(map(word_tokenize, x_data))\n",
    "x_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train set and valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into transet and valset\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N X_train :  6233\n",
      "N X_val :  1559\n"
     ]
    }
   ],
   "source": [
    "print('N X_train : ', len(X_train))\n",
    "print('N X_val : ', len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onhot encode to category\n",
    "def ohe2cat(label):\n",
    "    return np.argmax(label, axis=1)\n",
    "Y_train, Y_val = ohe2cat(Y_train), ohe2cat(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## compute number of occurence of each class\n",
    "\n",
    "class_name = [i for i in range(num_class)]\n",
    "class_n = [np.sum(Y_train==class_name[i])  for i in range(num_class)]\n",
    "\n",
    "plt.bar(range(num_class), class_n,color='rgb',tick_label=class_name)\n",
    "plt.title('Number of observations of each class')\n",
    "plt.show()\n",
    "\n",
    "## it is balanced, good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionnary that will map words to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "num_voc = 0\n",
    "for sentence in X_train:\n",
    "    for word in sentence:\n",
    "        if word not in dictionary.keys():\n",
    "            dictionary[word] = num_voc\n",
    "            num_voc += 1\n",
    "dictionary['UNK'] = num_voc\n",
    "num_voc+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(data):\n",
    "    d = []\n",
    "    for word in data:\n",
    "        if word in dictionary.keys():\n",
    "            d.append(dictionary[word])\n",
    "    return th.tensor(d)\n",
    "\n",
    "def to_index(data):\n",
    "    d = []\n",
    "    for word in data:\n",
    "        if word in dictionary.keys():\n",
    "            d.append(dictionary[word])\n",
    "        else:\n",
    "            d.append(dictionary['UNK'])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "\n",
    "- The dataset can not be encoded by one-hot, but embedding is a good choice. So it takes as input a tensor that is a sequence of integers indexing word embeddings.\n",
    "\n",
    "- a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_classifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, class_num):\n",
    "        super(My_classifier, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, 32)\n",
    "        self.linear2 = nn.Linear(32, class_num)\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.linear1.weight.data)\n",
    "        nn.init.kaiming_uniform_(self.linear2.weight.data)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).sum(0)\n",
    "        out = th.relu(self.linear1(embeds.view(1,-1)))\n",
    "        out = self.linear2(out)\n",
    "        #log_probs = th.log_softmax(out, dim=1)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate(model, datas, labels):\n",
    "    '''\n",
    "    function for evaluation\n",
    "    model : pytorch model\n",
    "    datas : dataset \n",
    "    labels : labels\n",
    "\n",
    "    return : accuracy\n",
    "    '''\n",
    "    # nb of good prediction\n",
    "    good = 0\n",
    "    # nb of false prediction\n",
    "    total = 0\n",
    "\n",
    "    # for each paire of x,y \n",
    "    for x,y in zip(datas,labels):\n",
    "        # make x to Tensor\n",
    "        x = to_tensor(x)\n",
    "        # if number of words in a sentence is smaller than size of slide window\n",
    "        total += 1\n",
    "        if x.size()[0] <= 0:\n",
    "            continue\n",
    "        # we break\n",
    "        # get result of model\n",
    "        out = model(x)\n",
    "    \n",
    "        if num_class == 2:\n",
    "            if (out[0].item() >= 0) == (y == 1.):\n",
    "                good += 1\n",
    "        else:\n",
    "        \n",
    "            if np.argmax(out.detach().numpy()) == y:\n",
    "                good += 1\n",
    "    return good/total\n",
    "\n",
    "def train(model, optimizer, criterion, data, labels):\n",
    "    total_loss = 0\n",
    "    data, labels = shuffle(data, labels)\n",
    "    for x, y in zip(data, labels):\n",
    "        # reset the gradient\n",
    "        optimizer.zero_grad()\n",
    "#         if to_tensor(x).size()[0] <= WINDOW-1:\n",
    "#             continue\n",
    "        # output of the model\n",
    "        output = model(to_tensor(x))\n",
    "        # compute the loss\n",
    "        loss = criterion(output, th.FloatTensor([y]))\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()  # compute gradient\n",
    "        #torch.nn.utils.clip_grad_value_(model.parameters(), 5.)  # clip gradient if its norm exceed 5\n",
    "        optimizer.step()  # update parameters\n",
    "    \n",
    "    return model,total_loss/len(data)\n",
    "\n",
    "def training_loop(model, optimizer, loss_function, n_epochs, datas, labels):\n",
    "    '''\n",
    "    training function\n",
    "    \n",
    "    model : the torch model\n",
    "    optimizer : optimizer \n",
    "    loss_function : loss function\n",
    "    n_epochs : number of epches\n",
    "    datas : dataset (x)\n",
    "    labels : labels (y)\n",
    "\n",
    "    return : the trained model, list of mean loss of each epochs, list of accuracy on dev set of each epochs, \n",
    "    '''\n",
    "    mean_losss = []\n",
    "    dev_accus = []\n",
    "    for e in range(n_epochs):\n",
    "        print(\"Epoch : \",e)\n",
    "        # train the model\n",
    "        model,mean_loss = train(model, optimizer, loss_function, datas, labels)\n",
    "        \n",
    "        #dev_accus.append(accuracy)  \n",
    "        mean_losss.append(mean_loss)\n",
    "\n",
    "        print('mean loss : ', mean_loss)\n",
    "        print('accuracy on dev set : ', evaluate(model, X_val, Y_val))\n",
    "    return model, mean_losss\n",
    "\n",
    "def training_loop_batch(model, optimizer, loss_function, n_epochs, datas, labels):\n",
    "    '''\n",
    "    training function\n",
    "    \n",
    "    model : the torch model\n",
    "    optimizer : optimizer \n",
    "    loss_function : loss function\n",
    "    n_epochs : number of epches\n",
    "    datas : dataset (x)\n",
    "    labels : labels (y)\n",
    "\n",
    "    return : the trained model, list of mean loss of each epochs, list of accuracy on dev set of each epochs, \n",
    "    '''\n",
    "    mean_losss = []\n",
    "    dev_accus = []\n",
    "    for e in range(n_epochs):\n",
    "        print(\"Epoch : \",e)\n",
    "        # train the model\n",
    "        model,mean_loss = train(model, optimizer, loss_function, datas, labels)\n",
    "        \n",
    "        #dev_accus.append(accuracy)  \n",
    "        mean_losss.append(mean_loss)\n",
    "\n",
    "        print('mean loss : ', mean_loss)\n",
    "        print('accuracy on dev set : ', evaluate(model, X_val, Y_val))\n",
    "    return model, mean_losss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My_classifier(\n",
      "  (embeddings): Embedding(13977, 40)\n",
      "  (linear1): Linear(in_features=40, out_features=32, bias=True)\n",
      "  (linear2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "Epoch :  0\n",
      "mean loss :  0.8675453754873159\n",
      "accuracy on dev set :  0.5490699166132136\n",
      "Epoch :  1\n",
      "mean loss :  0.720783124497693\n",
      "accuracy on dev set :  0.5644644002565747\n",
      "Epoch :  2\n",
      "mean loss :  0.706728803351242\n",
      "accuracy on dev set :  0.568313021167415\n",
      "Epoch :  3\n",
      "mean loss :  0.6855387551333049\n",
      "accuracy on dev set :  0.5400898011545863\n",
      "Epoch :  4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-e22db86b6b60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# training loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_losss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-154-88ea7bb843a9>\u001b[0m in \u001b[0;36mtraining_loop\u001b[1;34m(model, optimizer, loss_function, n_epochs, datas, labels)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m#dev_accus.append(accuracy)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-154-88ea7bb843a9>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion, data, labels)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# compute gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;31m#torch.nn.utils.clip_grad_value_(model.parameters(), 5.)  # clip gradient if its norm exceed 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 10\n",
    "WEIGHT_DECAY = 0.02\n",
    "DROP_OUT = None\n",
    "EMBED_DIM = 40\n",
    "\n",
    "model = My_classifier(num_voc, embedding_dim=EMBED_DIM, class_num=num_class)\n",
    "#model = CBOW_classifier(num_voc, embedding_dim=EMBED_DIM,)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)\n",
    "optimizer = th.optim.SGD(model.parameters(),lr=0.01)\n",
    "# training loop\n",
    "model, mean_losss = training_loop(model, optimizer, criterion, EPOCHS, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3598, grad_fn=<SelectBackward>)\n",
      "tensor(0.0906, grad_fn=<SelectBackward>)\n",
      "tensor(0.7581, grad_fn=<SelectBackward>)\n",
      "tensor(0.3864, grad_fn=<SelectBackward>)\n",
      "tensor(0.8227, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0879, grad_fn=<SelectBackward>)\n",
      "tensor(0.0574, grad_fn=<SelectBackward>)\n",
      "tensor(0.3250, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0057, grad_fn=<SelectBackward>)\n",
      "tensor(0.6958, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0576, grad_fn=<SelectBackward>)\n",
      "tensor(0.3782, grad_fn=<SelectBackward>)\n",
      "tensor(0.2242, grad_fn=<SelectBackward>)\n",
      "tensor(0.0764, grad_fn=<SelectBackward>)\n",
      "tensor(0.0150, grad_fn=<SelectBackward>)\n",
      "tensor(0.8491, grad_fn=<SelectBackward>)\n",
      "tensor(0.2401, grad_fn=<SelectBackward>)\n",
      "tensor(0.2970, grad_fn=<SelectBackward>)\n",
      "tensor(0.1886, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0629, grad_fn=<SelectBackward>)\n",
      "tensor(0.3533, grad_fn=<SelectBackward>)\n",
      "tensor(1.0392, grad_fn=<SelectBackward>)\n",
      "tensor(0.0415, grad_fn=<SelectBackward>)\n",
      "tensor(0.0556, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0028, grad_fn=<SelectBackward>)\n",
      "tensor(0.2365, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward>)\n",
      "tensor(0.3923, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0457, grad_fn=<SelectBackward>)\n",
      "tensor(0.0640, grad_fn=<SelectBackward>)\n",
      "tensor(0.2502, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0299, grad_fn=<SelectBackward>)\n",
      "tensor(0.0602, grad_fn=<SelectBackward>)\n",
      "tensor(0.1240, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2061, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1307, grad_fn=<SelectBackward>)\n",
      "tensor(0.1929, grad_fn=<SelectBackward>)\n",
      "tensor(0.6057, grad_fn=<SelectBackward>)\n",
      "tensor(0.3507, grad_fn=<SelectBackward>)\n",
      "tensor(0.4858, grad_fn=<SelectBackward>)\n",
      "tensor(0.0690, grad_fn=<SelectBackward>)\n",
      "tensor(0.1570, grad_fn=<SelectBackward>)\n",
      "tensor(0.1131, grad_fn=<SelectBackward>)\n",
      "tensor(0.0214, grad_fn=<SelectBackward>)\n",
      "tensor(0.3743, grad_fn=<SelectBackward>)\n",
      "tensor(0.0103, grad_fn=<SelectBackward>)\n",
      "tensor(0.1451, grad_fn=<SelectBackward>)\n",
      "tensor(0.1082, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1529, grad_fn=<SelectBackward>)\n",
      "tensor(0.2520, grad_fn=<SelectBackward>)\n",
      "tensor(0.1891, grad_fn=<SelectBackward>)\n",
      "tensor(1.0982, grad_fn=<SelectBackward>)\n",
      "tensor(0.1960, grad_fn=<SelectBackward>)\n",
      "tensor(0.4695, grad_fn=<SelectBackward>)\n",
      "tensor(0.1200, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0243, grad_fn=<SelectBackward>)\n",
      "tensor(0.0644, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0192, grad_fn=<SelectBackward>)\n",
      "tensor(0.6853, grad_fn=<SelectBackward>)\n",
      "tensor(0.0749, grad_fn=<SelectBackward>)\n",
      "tensor(0.0201, grad_fn=<SelectBackward>)\n",
      "tensor(1.0014, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0970, grad_fn=<SelectBackward>)\n",
      "tensor(0.3109, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0437, grad_fn=<SelectBackward>)\n",
      "tensor(0.0282, grad_fn=<SelectBackward>)\n",
      "tensor(0.1887, grad_fn=<SelectBackward>)\n",
      "tensor(0.1331, grad_fn=<SelectBackward>)\n",
      "tensor(0.1903, grad_fn=<SelectBackward>)\n",
      "tensor(0.4220, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0587, grad_fn=<SelectBackward>)\n",
      "tensor(0.8868, grad_fn=<SelectBackward>)\n",
      "tensor(0.2173, grad_fn=<SelectBackward>)\n",
      "tensor(0.1793, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0903, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0488, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0344, grad_fn=<SelectBackward>)\n",
      "tensor(1.0386, grad_fn=<SelectBackward>)\n",
      "tensor(0.3351, grad_fn=<SelectBackward>)\n",
      "tensor(0.1548, grad_fn=<SelectBackward>)\n",
      "tensor(0.0061, grad_fn=<SelectBackward>)\n",
      "tensor(0.9538, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0126, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0436, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1786, grad_fn=<SelectBackward>)\n",
      "tensor(0.2873, grad_fn=<SelectBackward>)\n",
      "tensor(0.0280, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1727, grad_fn=<SelectBackward>)\n",
      "tensor(0.4040, grad_fn=<SelectBackward>)\n",
      "tensor(0.2451, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0054, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0541, grad_fn=<SelectBackward>)\n",
      "tensor(0.1996, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0924, grad_fn=<SelectBackward>)\n",
      "tensor(0.4059, grad_fn=<SelectBackward>)\n",
      "tensor(0.6367, grad_fn=<SelectBackward>)\n",
      "tensor(0.5224, grad_fn=<SelectBackward>)\n",
      "tensor(1.0637, grad_fn=<SelectBackward>)\n",
      "tensor(0.6956, grad_fn=<SelectBackward>)\n",
      "tensor(0.2865, grad_fn=<SelectBackward>)\n",
      "tensor(0.9274, grad_fn=<SelectBackward>)\n",
      "tensor(0.0358, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1007, grad_fn=<SelectBackward>)\n",
      "tensor(0.2897, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0183, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0819, grad_fn=<SelectBackward>)\n",
      "tensor(0.0386, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0361, grad_fn=<SelectBackward>)\n",
      "tensor(0.9190, grad_fn=<SelectBackward>)\n",
      "tensor(0.0942, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0259, grad_fn=<SelectBackward>)\n",
      "tensor(0.6217, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0119, grad_fn=<SelectBackward>)\n",
      "tensor(0.2052, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0646, grad_fn=<SelectBackward>)\n",
      "tensor(0.6851, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0113, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0097, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1640, grad_fn=<SelectBackward>)\n",
      "tensor(0.2983, grad_fn=<SelectBackward>)\n",
      "tensor(0.7460, grad_fn=<SelectBackward>)\n",
      "tensor(0.0953, grad_fn=<SelectBackward>)\n",
      "tensor(0.0155, grad_fn=<SelectBackward>)\n",
      "tensor(0.1754, grad_fn=<SelectBackward>)\n",
      "tensor(0.2096, grad_fn=<SelectBackward>)\n",
      "tensor(0.3664, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0792, grad_fn=<SelectBackward>)\n",
      "tensor(0.1197, grad_fn=<SelectBackward>)\n",
      "tensor(0.4537, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1137, grad_fn=<SelectBackward>)\n",
      "tensor(1.0364, grad_fn=<SelectBackward>)\n",
      "tensor(0.1322, grad_fn=<SelectBackward>)\n",
      "tensor(0.9899, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0523, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1077, grad_fn=<SelectBackward>)\n",
      "tensor(0.5270, grad_fn=<SelectBackward>)\n",
      "tensor(0.3071, grad_fn=<SelectBackward>)\n",
      "tensor(0.2717, grad_fn=<SelectBackward>)\n",
      "tensor(0.1372, grad_fn=<SelectBackward>)\n",
      "tensor(0.1145, grad_fn=<SelectBackward>)\n",
      "tensor(0.0983, grad_fn=<SelectBackward>)\n",
      "tensor(0.2297, grad_fn=<SelectBackward>)\n",
      "tensor(0.0457, grad_fn=<SelectBackward>)\n",
      "tensor(0.1337, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0058, grad_fn=<SelectBackward>)\n",
      "tensor(0.0379, grad_fn=<SelectBackward>)\n",
      "tensor(0.3816, grad_fn=<SelectBackward>)\n",
      "tensor(0.3239, grad_fn=<SelectBackward>)\n",
      "tensor(0.0333, grad_fn=<SelectBackward>)\n",
      "tensor(0.3650, grad_fn=<SelectBackward>)\n",
      "tensor(0.1186, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1437, grad_fn=<SelectBackward>)\n",
      "tensor(0.1238, grad_fn=<SelectBackward>)\n",
      "tensor(0.8471, grad_fn=<SelectBackward>)\n",
      "tensor(0.5873, grad_fn=<SelectBackward>)\n",
      "tensor(0.1854, grad_fn=<SelectBackward>)\n",
      "tensor(0.5910, grad_fn=<SelectBackward>)\n",
      "tensor(0.1818, grad_fn=<SelectBackward>)\n",
      "tensor(0.3073, grad_fn=<SelectBackward>)\n",
      "tensor(0.1393, grad_fn=<SelectBackward>)\n",
      "tensor(0.7776, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1406, grad_fn=<SelectBackward>)\n",
      "tensor(0.1508, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1168, grad_fn=<SelectBackward>)\n",
      "tensor(0.8805, grad_fn=<SelectBackward>)\n",
      "tensor(0.3274, grad_fn=<SelectBackward>)\n",
      "tensor(0.3058, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2048, grad_fn=<SelectBackward>)\n",
      "tensor(0.1770, grad_fn=<SelectBackward>)\n",
      "tensor(0.0195, grad_fn=<SelectBackward>)\n",
      "tensor(0.0935, grad_fn=<SelectBackward>)\n",
      "tensor(0.6076, grad_fn=<SelectBackward>)\n",
      "tensor(0.0617, grad_fn=<SelectBackward>)\n",
      "tensor(0.3518, grad_fn=<SelectBackward>)\n",
      "tensor(0.5953, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0438, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0301, grad_fn=<SelectBackward>)\n",
      "tensor(0.3759, grad_fn=<SelectBackward>)\n",
      "tensor(0.7776, grad_fn=<SelectBackward>)\n",
      "tensor(0.2551, grad_fn=<SelectBackward>)\n",
      "tensor(0.7683, grad_fn=<SelectBackward>)\n",
      "tensor(0.0480, grad_fn=<SelectBackward>)\n",
      "tensor(0.7547, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0414, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0767, grad_fn=<SelectBackward>)\n",
      "tensor(0.4513, grad_fn=<SelectBackward>)\n",
      "tensor(0.5651, grad_fn=<SelectBackward>)\n",
      "tensor(0.6332, grad_fn=<SelectBackward>)\n",
      "tensor(0.1422, grad_fn=<SelectBackward>)\n",
      "tensor(0.0847, grad_fn=<SelectBackward>)\n",
      "tensor(0.1464, grad_fn=<SelectBackward>)\n",
      "tensor(0.0379, grad_fn=<SelectBackward>)\n",
      "tensor(0.0802, grad_fn=<SelectBackward>)\n",
      "tensor(0.1371, grad_fn=<SelectBackward>)\n",
      "tensor(0.3620, grad_fn=<SelectBackward>)\n",
      "tensor(0.7830, grad_fn=<SelectBackward>)\n",
      "tensor(1.1424, grad_fn=<SelectBackward>)\n",
      "tensor(0.2672, grad_fn=<SelectBackward>)\n",
      "tensor(0.0330, grad_fn=<SelectBackward>)\n",
      "tensor(0.1607, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0055, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0275, grad_fn=<SelectBackward>)\n",
      "tensor(0.0964, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0677, grad_fn=<SelectBackward>)\n",
      "tensor(0.2035, grad_fn=<SelectBackward>)\n",
      "tensor(0.4307, grad_fn=<SelectBackward>)\n",
      "tensor(0.5261, grad_fn=<SelectBackward>)\n",
      "tensor(0.4701, grad_fn=<SelectBackward>)\n",
      "tensor(0.2076, grad_fn=<SelectBackward>)\n",
      "tensor(0.1304, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0740, grad_fn=<SelectBackward>)\n",
      "tensor(0.5257, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0865, grad_fn=<SelectBackward>)\n",
      "tensor(0.0872, grad_fn=<SelectBackward>)\n",
      "tensor(0.6651, grad_fn=<SelectBackward>)\n",
      "tensor(0.1310, grad_fn=<SelectBackward>)\n",
      "tensor(0.5429, grad_fn=<SelectBackward>)\n",
      "tensor(0.1550, grad_fn=<SelectBackward>)\n",
      "tensor(0.0056, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0281, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0784, grad_fn=<SelectBackward>)\n",
      "tensor(0.2020, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0738, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1586, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0280, grad_fn=<SelectBackward>)\n",
      "tensor(0.1420, grad_fn=<SelectBackward>)\n",
      "tensor(0.7027, grad_fn=<SelectBackward>)\n",
      "tensor(0.1474, grad_fn=<SelectBackward>)\n",
      "tensor(0.3647, grad_fn=<SelectBackward>)\n",
      "tensor(0.0084, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1286, grad_fn=<SelectBackward>)\n",
      "tensor(0.2451, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1884, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1536, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1581, grad_fn=<SelectBackward>)\n",
      "tensor(0.1710, grad_fn=<SelectBackward>)\n",
      "tensor(0.1249, grad_fn=<SelectBackward>)\n",
      "tensor(0.0032, grad_fn=<SelectBackward>)\n",
      "tensor(0.3418, grad_fn=<SelectBackward>)\n",
      "tensor(0.4247, grad_fn=<SelectBackward>)\n",
      "tensor(0.0706, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0406, grad_fn=<SelectBackward>)\n",
      "tensor(0.1300, grad_fn=<SelectBackward>)\n",
      "tensor(0.3038, grad_fn=<SelectBackward>)\n",
      "tensor(0.3781, grad_fn=<SelectBackward>)\n",
      "tensor(0.6805, grad_fn=<SelectBackward>)\n",
      "tensor(0.1564, grad_fn=<SelectBackward>)\n",
      "tensor(0.2588, grad_fn=<SelectBackward>)\n",
      "tensor(0.0772, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1835, grad_fn=<SelectBackward>)\n",
      "tensor(0.8205, grad_fn=<SelectBackward>)\n",
      "tensor(0.2005, grad_fn=<SelectBackward>)\n",
      "tensor(0.0867, grad_fn=<SelectBackward>)\n",
      "tensor(0.4766, grad_fn=<SelectBackward>)\n",
      "tensor(0.1295, grad_fn=<SelectBackward>)\n",
      "tensor(0.2565, grad_fn=<SelectBackward>)\n",
      "tensor(0.3845, grad_fn=<SelectBackward>)\n",
      "tensor(0.0673, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0761, grad_fn=<SelectBackward>)\n",
      "tensor(0.0717, grad_fn=<SelectBackward>)\n",
      "tensor(0.3391, grad_fn=<SelectBackward>)\n",
      "tensor(0.3434, grad_fn=<SelectBackward>)\n",
      "tensor(0.2403, grad_fn=<SelectBackward>)\n",
      "tensor(0.2475, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0320, grad_fn=<SelectBackward>)\n",
      "tensor(0.3132, grad_fn=<SelectBackward>)\n",
      "tensor(0.1845, grad_fn=<SelectBackward>)\n",
      "tensor(0.2093, grad_fn=<SelectBackward>)\n",
      "tensor(0.0017, grad_fn=<SelectBackward>)\n",
      "tensor(0.0689, grad_fn=<SelectBackward>)\n",
      "tensor(0.1837, grad_fn=<SelectBackward>)\n",
      "tensor(0.0229, grad_fn=<SelectBackward>)\n",
      "tensor(0.2114, grad_fn=<SelectBackward>)\n",
      "tensor(0.2254, grad_fn=<SelectBackward>)\n",
      "tensor(0.3833, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward>)\n",
      "tensor(0.8452, grad_fn=<SelectBackward>)\n",
      "tensor(0.5954, grad_fn=<SelectBackward>)\n",
      "tensor(0.2155, grad_fn=<SelectBackward>)\n",
      "tensor(0.0696, grad_fn=<SelectBackward>)\n",
      "tensor(0.2330, grad_fn=<SelectBackward>)\n",
      "tensor(0.0249, grad_fn=<SelectBackward>)\n",
      "tensor(0.0607, grad_fn=<SelectBackward>)\n",
      "tensor(0.6702, grad_fn=<SelectBackward>)\n",
      "tensor(0.1186, grad_fn=<SelectBackward>)\n",
      "tensor(0.0940, grad_fn=<SelectBackward>)\n",
      "tensor(0.1424, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0934, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1203, grad_fn=<SelectBackward>)\n",
      "tensor(0.2033, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1367, grad_fn=<SelectBackward>)\n",
      "tensor(0.0781, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0977, grad_fn=<SelectBackward>)\n",
      "tensor(0.0049, grad_fn=<SelectBackward>)\n",
      "tensor(0.5433, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0094, grad_fn=<SelectBackward>)\n",
      "tensor(0.0720, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2588, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0737, grad_fn=<SelectBackward>)\n",
      "tensor(0.7597, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0579, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0806, grad_fn=<SelectBackward>)\n",
      "tensor(0.6652, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0341, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward>)\n",
      "tensor(0.5570, grad_fn=<SelectBackward>)\n",
      "tensor(0.1295, grad_fn=<SelectBackward>)\n",
      "tensor(0.4843, grad_fn=<SelectBackward>)\n",
      "tensor(0.0866, grad_fn=<SelectBackward>)\n",
      "tensor(0.4224, grad_fn=<SelectBackward>)\n",
      "tensor(0.2384, grad_fn=<SelectBackward>)\n",
      "tensor(0.3932, grad_fn=<SelectBackward>)\n",
      "tensor(0.6872, grad_fn=<SelectBackward>)\n",
      "tensor(0.6490, grad_fn=<SelectBackward>)\n",
      "tensor(0.0984, grad_fn=<SelectBackward>)\n",
      "tensor(0.4502, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0105, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1580, grad_fn=<SelectBackward>)\n",
      "tensor(0.7141, grad_fn=<SelectBackward>)\n",
      "tensor(0.2391, grad_fn=<SelectBackward>)\n",
      "tensor(0.0216, grad_fn=<SelectBackward>)\n",
      "tensor(0.2464, grad_fn=<SelectBackward>)\n",
      "tensor(0.0293, grad_fn=<SelectBackward>)\n",
      "tensor(0.2226, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0259, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0146, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2212, grad_fn=<SelectBackward>)\n",
      "tensor(0.0294, grad_fn=<SelectBackward>)\n",
      "tensor(0.1894, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0194, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0385, grad_fn=<SelectBackward>)\n",
      "tensor(0.6261, grad_fn=<SelectBackward>)\n",
      "tensor(0.2017, grad_fn=<SelectBackward>)\n",
      "tensor(0.3496, grad_fn=<SelectBackward>)\n",
      "tensor(0.2077, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1363, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0196, grad_fn=<SelectBackward>)\n",
      "tensor(1.0615, grad_fn=<SelectBackward>)\n",
      "tensor(0.3324, grad_fn=<SelectBackward>)\n",
      "tensor(0.8204, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0865, grad_fn=<SelectBackward>)\n",
      "tensor(0.0049, grad_fn=<SelectBackward>)\n",
      "tensor(0.8303, grad_fn=<SelectBackward>)\n",
      "tensor(0.4559, grad_fn=<SelectBackward>)\n",
      "tensor(0.0522, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1935, grad_fn=<SelectBackward>)\n",
      "tensor(0.1377, grad_fn=<SelectBackward>)\n",
      "tensor(0.7967, grad_fn=<SelectBackward>)\n",
      "tensor(0.2264, grad_fn=<SelectBackward>)\n",
      "tensor(0.2683, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0303, grad_fn=<SelectBackward>)\n",
      "tensor(0.0412, grad_fn=<SelectBackward>)\n",
      "tensor(0.2191, grad_fn=<SelectBackward>)\n",
      "tensor(0.0254, grad_fn=<SelectBackward>)\n",
      "tensor(0.3451, grad_fn=<SelectBackward>)\n",
      "tensor(0.2879, grad_fn=<SelectBackward>)\n",
      "tensor(0.1898, grad_fn=<SelectBackward>)\n",
      "tensor(0.2329, grad_fn=<SelectBackward>)\n",
      "tensor(0.4052, grad_fn=<SelectBackward>)\n",
      "tensor(0.1944, grad_fn=<SelectBackward>)\n",
      "tensor(0.5292, grad_fn=<SelectBackward>)\n",
      "tensor(0.5330, grad_fn=<SelectBackward>)\n",
      "tensor(0.2879, grad_fn=<SelectBackward>)\n",
      "tensor(0.5017, grad_fn=<SelectBackward>)\n",
      "tensor(0.2501, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0726, grad_fn=<SelectBackward>)\n",
      "tensor(0.2694, grad_fn=<SelectBackward>)\n",
      "tensor(0.6815, grad_fn=<SelectBackward>)\n",
      "tensor(0.0622, grad_fn=<SelectBackward>)\n",
      "tensor(0.3249, grad_fn=<SelectBackward>)\n",
      "tensor(0.8485, grad_fn=<SelectBackward>)\n",
      "tensor(0.6934, grad_fn=<SelectBackward>)\n",
      "tensor(0.2625, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0227, grad_fn=<SelectBackward>)\n",
      "tensor(0.2291, grad_fn=<SelectBackward>)\n",
      "tensor(0.4132, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0039, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0883, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1822, grad_fn=<SelectBackward>)\n",
      "tensor(0.6666, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward>)\n",
      "tensor(0.1938, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1277, grad_fn=<SelectBackward>)\n",
      "tensor(0.2155, grad_fn=<SelectBackward>)\n",
      "tensor(0.1619, grad_fn=<SelectBackward>)\n",
      "tensor(0.6084, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0859, grad_fn=<SelectBackward>)\n",
      "tensor(0.1101, grad_fn=<SelectBackward>)\n",
      "tensor(0.6927, grad_fn=<SelectBackward>)\n",
      "tensor(0.0189, grad_fn=<SelectBackward>)\n",
      "tensor(0.1171, grad_fn=<SelectBackward>)\n",
      "tensor(0.8778, grad_fn=<SelectBackward>)\n",
      "tensor(0.0401, grad_fn=<SelectBackward>)\n",
      "tensor(0.2408, grad_fn=<SelectBackward>)\n",
      "tensor(0.2179, grad_fn=<SelectBackward>)\n",
      "tensor(0.9540, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0736, grad_fn=<SelectBackward>)\n",
      "tensor(0.0349, grad_fn=<SelectBackward>)\n",
      "tensor(0.0906, grad_fn=<SelectBackward>)\n",
      "tensor(0.0647, grad_fn=<SelectBackward>)\n",
      "tensor(0.7592, grad_fn=<SelectBackward>)\n",
      "tensor(0.7766, grad_fn=<SelectBackward>)\n",
      "tensor(0.5130, grad_fn=<SelectBackward>)\n",
      "tensor(0.2592, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0456, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0264, grad_fn=<SelectBackward>)\n",
      "tensor(0.9008, grad_fn=<SelectBackward>)\n",
      "tensor(0.1622, grad_fn=<SelectBackward>)\n",
      "tensor(0.8539, grad_fn=<SelectBackward>)\n",
      "tensor(0.0744, grad_fn=<SelectBackward>)\n",
      "tensor(0.0658, grad_fn=<SelectBackward>)\n",
      "tensor(0.3876, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0239, grad_fn=<SelectBackward>)\n",
      "tensor(0.0998, grad_fn=<SelectBackward>)\n",
      "tensor(0.5362, grad_fn=<SelectBackward>)\n",
      "tensor(0.2263, grad_fn=<SelectBackward>)\n",
      "tensor(0.1110, grad_fn=<SelectBackward>)\n",
      "tensor(0.0736, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1538, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1172, grad_fn=<SelectBackward>)\n",
      "tensor(1.1775, grad_fn=<SelectBackward>)\n",
      "tensor(0.7708, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1145, grad_fn=<SelectBackward>)\n",
      "tensor(0.0675, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1667, grad_fn=<SelectBackward>)\n",
      "tensor(0.2417, grad_fn=<SelectBackward>)\n",
      "tensor(0.9110, grad_fn=<SelectBackward>)\n",
      "tensor(0.1388, grad_fn=<SelectBackward>)\n",
      "tensor(0.0636, grad_fn=<SelectBackward>)\n",
      "tensor(0.1092, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0509, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1469, grad_fn=<SelectBackward>)\n",
      "tensor(0.0073, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2158, grad_fn=<SelectBackward>)\n",
      "tensor(0.5469, grad_fn=<SelectBackward>)\n",
      "tensor(0.1583, grad_fn=<SelectBackward>)\n",
      "tensor(0.1091, grad_fn=<SelectBackward>)\n",
      "tensor(0.0224, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1513, grad_fn=<SelectBackward>)\n",
      "tensor(0.0271, grad_fn=<SelectBackward>)\n",
      "tensor(0.0336, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1963, grad_fn=<SelectBackward>)\n",
      "tensor(0.0921, grad_fn=<SelectBackward>)\n",
      "tensor(0.6398, grad_fn=<SelectBackward>)\n",
      "tensor(0.2217, grad_fn=<SelectBackward>)\n",
      "tensor(0.8579, grad_fn=<SelectBackward>)\n",
      "tensor(0.5529, grad_fn=<SelectBackward>)\n",
      "tensor(0.1899, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0186, grad_fn=<SelectBackward>)\n",
      "tensor(0.0261, grad_fn=<SelectBackward>)\n",
      "tensor(0.0659, grad_fn=<SelectBackward>)\n",
      "tensor(0.2162, grad_fn=<SelectBackward>)\n",
      "tensor(0.6643, grad_fn=<SelectBackward>)\n",
      "tensor(0.4399, grad_fn=<SelectBackward>)\n",
      "tensor(0.1794, grad_fn=<SelectBackward>)\n",
      "tensor(0.4632, grad_fn=<SelectBackward>)\n",
      "tensor(0.2055, grad_fn=<SelectBackward>)\n",
      "tensor(0.0753, grad_fn=<SelectBackward>)\n",
      "tensor(0.2018, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0198, grad_fn=<SelectBackward>)\n",
      "tensor(0.3527, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0446, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0974, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0157, grad_fn=<SelectBackward>)\n",
      "tensor(0.1917, grad_fn=<SelectBackward>)\n",
      "tensor(0.0759, grad_fn=<SelectBackward>)\n",
      "tensor(0.0609, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0379, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0453, grad_fn=<SelectBackward>)\n",
      "tensor(0.0164, grad_fn=<SelectBackward>)\n",
      "tensor(0.9537, grad_fn=<SelectBackward>)\n",
      "tensor(0.2361, grad_fn=<SelectBackward>)\n",
      "tensor(1.0298, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1211, grad_fn=<SelectBackward>)\n",
      "tensor(0.5567, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2302, grad_fn=<SelectBackward>)\n",
      "tensor(0.0421, grad_fn=<SelectBackward>)\n",
      "tensor(0.2578, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0165, grad_fn=<SelectBackward>)\n",
      "tensor(1.2081, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1153, grad_fn=<SelectBackward>)\n",
      "tensor(0.2429, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0456, grad_fn=<SelectBackward>)\n",
      "tensor(0.1579, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0465, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0304, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1565, grad_fn=<SelectBackward>)\n",
      "tensor(0.4545, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0307, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0498, grad_fn=<SelectBackward>)\n",
      "tensor(0.0009, grad_fn=<SelectBackward>)\n",
      "tensor(0.1924, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0604, grad_fn=<SelectBackward>)\n",
      "tensor(0.5455, grad_fn=<SelectBackward>)\n",
      "tensor(1.1273, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0673, grad_fn=<SelectBackward>)\n",
      "tensor(0.1575, grad_fn=<SelectBackward>)\n",
      "tensor(0.3316, grad_fn=<SelectBackward>)\n",
      "tensor(0.8574, grad_fn=<SelectBackward>)\n",
      "tensor(0.1699, grad_fn=<SelectBackward>)\n",
      "tensor(0.0558, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2348, grad_fn=<SelectBackward>)\n",
      "tensor(0.0932, grad_fn=<SelectBackward>)\n",
      "tensor(0.0358, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0347, grad_fn=<SelectBackward>)\n",
      "tensor(0.0324, grad_fn=<SelectBackward>)\n",
      "tensor(0.1646, grad_fn=<SelectBackward>)\n",
      "tensor(0.0637, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1894, grad_fn=<SelectBackward>)\n",
      "tensor(0.1140, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1730, grad_fn=<SelectBackward>)\n",
      "tensor(0.2211, grad_fn=<SelectBackward>)\n",
      "tensor(0.6684, grad_fn=<SelectBackward>)\n",
      "tensor(0.4652, grad_fn=<SelectBackward>)\n",
      "tensor(0.2646, grad_fn=<SelectBackward>)\n",
      "tensor(0.1718, grad_fn=<SelectBackward>)\n",
      "tensor(0.0208, grad_fn=<SelectBackward>)\n",
      "tensor(0.2995, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0002, grad_fn=<SelectBackward>)\n",
      "tensor(0.2702, grad_fn=<SelectBackward>)\n",
      "tensor(0.7663, grad_fn=<SelectBackward>)\n",
      "tensor(0.8845, grad_fn=<SelectBackward>)\n",
      "tensor(0.9740, grad_fn=<SelectBackward>)\n",
      "tensor(1.0188, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0664, grad_fn=<SelectBackward>)\n",
      "tensor(0.2554, grad_fn=<SelectBackward>)\n",
      "tensor(0.1072, grad_fn=<SelectBackward>)\n",
      "tensor(0.7598, grad_fn=<SelectBackward>)\n",
      "tensor(0.1174, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0814, grad_fn=<SelectBackward>)\n",
      "tensor(0.3129, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2198, grad_fn=<SelectBackward>)\n",
      "tensor(0.3796, grad_fn=<SelectBackward>)\n",
      "tensor(0.3434, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2225, grad_fn=<SelectBackward>)\n",
      "tensor(0.0549, grad_fn=<SelectBackward>)\n",
      "tensor(0.3576, grad_fn=<SelectBackward>)\n",
      "tensor(0.0341, grad_fn=<SelectBackward>)\n",
      "tensor(0.0892, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0151, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1291, grad_fn=<SelectBackward>)\n",
      "tensor(0.0884, grad_fn=<SelectBackward>)\n",
      "tensor(0.1105, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0167, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0274, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0841, grad_fn=<SelectBackward>)\n",
      "tensor(0.1556, grad_fn=<SelectBackward>)\n",
      "tensor(0.7367, grad_fn=<SelectBackward>)\n",
      "tensor(0.5329, grad_fn=<SelectBackward>)\n",
      "tensor(0.4770, grad_fn=<SelectBackward>)\n",
      "tensor(0.2081, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0285, grad_fn=<SelectBackward>)\n",
      "tensor(0.2647, grad_fn=<SelectBackward>)\n",
      "tensor(0.7567, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0115, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0159, grad_fn=<SelectBackward>)\n",
      "tensor(0.0111, grad_fn=<SelectBackward>)\n",
      "tensor(0.2561, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0308, grad_fn=<SelectBackward>)\n",
      "tensor(0.3402, grad_fn=<SelectBackward>)\n",
      "tensor(0.0340, grad_fn=<SelectBackward>)\n",
      "tensor(0.0343, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0337, grad_fn=<SelectBackward>)\n",
      "tensor(0.7158, grad_fn=<SelectBackward>)\n",
      "tensor(0.1017, grad_fn=<SelectBackward>)\n",
      "tensor(0.2832, grad_fn=<SelectBackward>)\n",
      "tensor(0.0513, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0477, grad_fn=<SelectBackward>)\n",
      "tensor(0.1030, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1163, grad_fn=<SelectBackward>)\n",
      "tensor(0.1942, grad_fn=<SelectBackward>)\n",
      "tensor(0.2255, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1657, grad_fn=<SelectBackward>)\n",
      "tensor(0.2267, grad_fn=<SelectBackward>)\n",
      "tensor(0.0895, grad_fn=<SelectBackward>)\n",
      "tensor(0.0535, grad_fn=<SelectBackward>)\n",
      "tensor(0.0351, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1005, grad_fn=<SelectBackward>)\n",
      "tensor(0.3811, grad_fn=<SelectBackward>)\n",
      "tensor(0.1048, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0507, grad_fn=<SelectBackward>)\n",
      "tensor(0.1772, grad_fn=<SelectBackward>)\n",
      "tensor(0.2341, grad_fn=<SelectBackward>)\n",
      "tensor(0.4275, grad_fn=<SelectBackward>)\n",
      "tensor(0.2441, grad_fn=<SelectBackward>)\n",
      "tensor(0.1273, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0626, grad_fn=<SelectBackward>)\n",
      "tensor(0.3886, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1190, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0021, grad_fn=<SelectBackward>)\n",
      "tensor(0.1838, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0398, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1377, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1388, grad_fn=<SelectBackward>)\n",
      "tensor(0.3015, grad_fn=<SelectBackward>)\n",
      "tensor(0.1754, grad_fn=<SelectBackward>)\n",
      "tensor(0.6570, grad_fn=<SelectBackward>)\n",
      "tensor(0.3354, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0395, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1371, grad_fn=<SelectBackward>)\n",
      "tensor(1.0096, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0818, grad_fn=<SelectBackward>)\n",
      "tensor(0.4019, grad_fn=<SelectBackward>)\n",
      "tensor(0.2113, grad_fn=<SelectBackward>)\n",
      "tensor(0.0794, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0236, grad_fn=<SelectBackward>)\n",
      "tensor(0.5000, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1393, grad_fn=<SelectBackward>)\n",
      "tensor(0.2958, grad_fn=<SelectBackward>)\n",
      "tensor(0.0753, grad_fn=<SelectBackward>)\n",
      "tensor(0.1990, grad_fn=<SelectBackward>)\n",
      "tensor(0.3110, grad_fn=<SelectBackward>)\n",
      "tensor(0.1491, grad_fn=<SelectBackward>)\n",
      "tensor(0.1378, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1943, grad_fn=<SelectBackward>)\n",
      "tensor(0.1518, grad_fn=<SelectBackward>)\n",
      "tensor(0.2136, grad_fn=<SelectBackward>)\n",
      "tensor(0.5427, grad_fn=<SelectBackward>)\n",
      "tensor(0.1224, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1220, grad_fn=<SelectBackward>)\n",
      "tensor(0.2804, grad_fn=<SelectBackward>)\n",
      "tensor(0.0713, grad_fn=<SelectBackward>)\n",
      "tensor(0.1373, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1802, grad_fn=<SelectBackward>)\n",
      "tensor(0.5686, grad_fn=<SelectBackward>)\n",
      "tensor(0.3858, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0386, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1796, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1482, grad_fn=<SelectBackward>)\n",
      "tensor(0.1992, grad_fn=<SelectBackward>)\n",
      "tensor(0.3206, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0976, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1279, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2609, grad_fn=<SelectBackward>)\n",
      "tensor(0.1711, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0704, grad_fn=<SelectBackward>)\n",
      "tensor(0.1612, grad_fn=<SelectBackward>)\n",
      "tensor(0.1425, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2051, grad_fn=<SelectBackward>)\n",
      "tensor(0.1357, grad_fn=<SelectBackward>)\n",
      "tensor(0.2310, grad_fn=<SelectBackward>)\n",
      "tensor(0.0596, grad_fn=<SelectBackward>)\n",
      "tensor(0.3951, grad_fn=<SelectBackward>)\n",
      "tensor(0.0889, grad_fn=<SelectBackward>)\n",
      "tensor(0.1485, grad_fn=<SelectBackward>)\n",
      "tensor(0.8575, grad_fn=<SelectBackward>)\n",
      "tensor(0.2001, grad_fn=<SelectBackward>)\n",
      "tensor(0.0821, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1027, grad_fn=<SelectBackward>)\n",
      "tensor(0.1992, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0472, grad_fn=<SelectBackward>)\n",
      "tensor(0.0491, grad_fn=<SelectBackward>)\n",
      "tensor(0.4979, grad_fn=<SelectBackward>)\n",
      "tensor(0.2842, grad_fn=<SelectBackward>)\n",
      "tensor(0.1532, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0056, grad_fn=<SelectBackward>)\n",
      "tensor(0.4048, grad_fn=<SelectBackward>)\n",
      "tensor(0.4027, grad_fn=<SelectBackward>)\n",
      "tensor(0.2560, grad_fn=<SelectBackward>)\n",
      "tensor(0.5279, grad_fn=<SelectBackward>)\n",
      "tensor(0.5319, grad_fn=<SelectBackward>)\n",
      "tensor(0.0716, grad_fn=<SelectBackward>)\n",
      "tensor(0.2383, grad_fn=<SelectBackward>)\n",
      "tensor(0.1030, grad_fn=<SelectBackward>)\n",
      "tensor(0.3477, grad_fn=<SelectBackward>)\n",
      "tensor(0.1330, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1245, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6820, grad_fn=<SelectBackward>)\n",
      "tensor(0.1342, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1195, grad_fn=<SelectBackward>)\n",
      "tensor(0.1040, grad_fn=<SelectBackward>)\n",
      "tensor(0.3097, grad_fn=<SelectBackward>)\n",
      "tensor(0.9103, grad_fn=<SelectBackward>)\n",
      "tensor(0.4938, grad_fn=<SelectBackward>)\n",
      "tensor(0.1488, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0711, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0746, grad_fn=<SelectBackward>)\n",
      "tensor(0.2593, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0779, grad_fn=<SelectBackward>)\n",
      "tensor(0.3486, grad_fn=<SelectBackward>)\n",
      "tensor(0.2985, grad_fn=<SelectBackward>)\n",
      "tensor(0.2034, grad_fn=<SelectBackward>)\n",
      "tensor(0.0974, grad_fn=<SelectBackward>)\n",
      "tensor(0.4299, grad_fn=<SelectBackward>)\n",
      "tensor(0.2869, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0900, grad_fn=<SelectBackward>)\n",
      "tensor(0.3751, grad_fn=<SelectBackward>)\n",
      "tensor(0.3302, grad_fn=<SelectBackward>)\n",
      "tensor(0.0405, grad_fn=<SelectBackward>)\n",
      "tensor(0.3909, grad_fn=<SelectBackward>)\n",
      "tensor(0.9920, grad_fn=<SelectBackward>)\n",
      "tensor(0.3212, grad_fn=<SelectBackward>)\n",
      "tensor(0.0199, grad_fn=<SelectBackward>)\n",
      "tensor(0.1483, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1139, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0382, grad_fn=<SelectBackward>)\n",
      "tensor(0.1892, grad_fn=<SelectBackward>)\n",
      "tensor(0.4327, grad_fn=<SelectBackward>)\n",
      "tensor(0.9204, grad_fn=<SelectBackward>)\n",
      "tensor(0.0363, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1806, grad_fn=<SelectBackward>)\n",
      "tensor(0.2565, grad_fn=<SelectBackward>)\n",
      "tensor(0.3751, grad_fn=<SelectBackward>)\n",
      "tensor(0.0744, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0924, grad_fn=<SelectBackward>)\n",
      "tensor(0.3161, grad_fn=<SelectBackward>)\n",
      "tensor(0.3745, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1779, grad_fn=<SelectBackward>)\n",
      "tensor(0.7903, grad_fn=<SelectBackward>)\n",
      "tensor(0.0248, grad_fn=<SelectBackward>)\n",
      "tensor(0.1824, grad_fn=<SelectBackward>)\n",
      "tensor(0.2535, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0092, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2158, grad_fn=<SelectBackward>)\n",
      "tensor(0.8279, grad_fn=<SelectBackward>)\n",
      "tensor(0.3746, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0612, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0343, grad_fn=<SelectBackward>)\n",
      "tensor(0.2675, grad_fn=<SelectBackward>)\n",
      "tensor(0.1620, grad_fn=<SelectBackward>)\n",
      "tensor(0.3060, grad_fn=<SelectBackward>)\n",
      "tensor(0.2957, grad_fn=<SelectBackward>)\n",
      "tensor(0.1226, grad_fn=<SelectBackward>)\n",
      "tensor(0.5189, grad_fn=<SelectBackward>)\n",
      "tensor(0.9622, grad_fn=<SelectBackward>)\n",
      "tensor(0.0668, grad_fn=<SelectBackward>)\n",
      "tensor(0.0221, grad_fn=<SelectBackward>)\n",
      "tensor(0.2298, grad_fn=<SelectBackward>)\n",
      "tensor(0.2833, grad_fn=<SelectBackward>)\n",
      "tensor(0.0797, grad_fn=<SelectBackward>)\n",
      "tensor(0.2857, grad_fn=<SelectBackward>)\n",
      "tensor(1.0165, grad_fn=<SelectBackward>)\n",
      "tensor(0.1843, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0187, grad_fn=<SelectBackward>)\n",
      "tensor(0.5730, grad_fn=<SelectBackward>)\n",
      "tensor(0.4474, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0070, grad_fn=<SelectBackward>)\n",
      "tensor(0.2193, grad_fn=<SelectBackward>)\n",
      "tensor(0.0385, grad_fn=<SelectBackward>)\n",
      "tensor(0.3477, grad_fn=<SelectBackward>)\n",
      "tensor(0.0883, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0725, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1197, grad_fn=<SelectBackward>)\n",
      "tensor(0.6843, grad_fn=<SelectBackward>)\n",
      "tensor(0.0424, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0353, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0290, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0778, grad_fn=<SelectBackward>)\n",
      "tensor(0.3479, grad_fn=<SelectBackward>)\n",
      "tensor(0.1687, grad_fn=<SelectBackward>)\n",
      "tensor(0.2635, grad_fn=<SelectBackward>)\n",
      "tensor(0.3235, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0199, grad_fn=<SelectBackward>)\n",
      "tensor(0.0975, grad_fn=<SelectBackward>)\n",
      "tensor(0.1345, grad_fn=<SelectBackward>)\n",
      "tensor(0.6030, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1218, grad_fn=<SelectBackward>)\n",
      "tensor(0.6583, grad_fn=<SelectBackward>)\n",
      "tensor(0.0650, grad_fn=<SelectBackward>)\n",
      "tensor(0.0264, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0747, grad_fn=<SelectBackward>)\n",
      "tensor(0.0602, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2279, grad_fn=<SelectBackward>)\n",
      "tensor(0.0737, grad_fn=<SelectBackward>)\n",
      "tensor(0.2849, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1117, grad_fn=<SelectBackward>)\n",
      "tensor(0.5275, grad_fn=<SelectBackward>)\n",
      "tensor(0.0715, grad_fn=<SelectBackward>)\n",
      "tensor(0.1612, grad_fn=<SelectBackward>)\n",
      "tensor(0.0570, grad_fn=<SelectBackward>)\n",
      "tensor(0.4208, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0114, grad_fn=<SelectBackward>)\n",
      "tensor(0.0904, grad_fn=<SelectBackward>)\n",
      "tensor(0.2621, grad_fn=<SelectBackward>)\n",
      "tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "tensor(0.0359, grad_fn=<SelectBackward>)\n",
      "tensor(0.1598, grad_fn=<SelectBackward>)\n",
      "tensor(0.3530, grad_fn=<SelectBackward>)\n",
      "tensor(0.0341, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2559, grad_fn=<SelectBackward>)\n",
      "tensor(0.3659, grad_fn=<SelectBackward>)\n",
      "tensor(0.1206, grad_fn=<SelectBackward>)\n",
      "tensor(0.4612, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0205, grad_fn=<SelectBackward>)\n",
      "tensor(0.3288, grad_fn=<SelectBackward>)\n",
      "tensor(1.0573, grad_fn=<SelectBackward>)\n",
      "tensor(0.2407, grad_fn=<SelectBackward>)\n",
      "tensor(0.1252, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1751, grad_fn=<SelectBackward>)\n",
      "tensor(0.1013, grad_fn=<SelectBackward>)\n",
      "tensor(0.1122, grad_fn=<SelectBackward>)\n",
      "tensor(0.5190, grad_fn=<SelectBackward>)\n",
      "tensor(0.1450, grad_fn=<SelectBackward>)\n",
      "tensor(0.7068, grad_fn=<SelectBackward>)\n",
      "tensor(0.1243, grad_fn=<SelectBackward>)\n",
      "tensor(1.0100, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0039, grad_fn=<SelectBackward>)\n",
      "tensor(0.4230, grad_fn=<SelectBackward>)\n",
      "tensor(0.0732, grad_fn=<SelectBackward>)\n",
      "tensor(0.2887, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0821, grad_fn=<SelectBackward>)\n",
      "tensor(0.2953, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0097, grad_fn=<SelectBackward>)\n",
      "tensor(0.3567, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0643, grad_fn=<SelectBackward>)\n",
      "tensor(0.0745, grad_fn=<SelectBackward>)\n",
      "tensor(0.3224, grad_fn=<SelectBackward>)\n",
      "tensor(0.4260, grad_fn=<SelectBackward>)\n",
      "tensor(0.3200, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1826, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0619, grad_fn=<SelectBackward>)\n",
      "tensor(0.2385, grad_fn=<SelectBackward>)\n",
      "tensor(0.0968, grad_fn=<SelectBackward>)\n",
      "tensor(0.0506, grad_fn=<SelectBackward>)\n",
      "tensor(0.0576, grad_fn=<SelectBackward>)\n",
      "tensor(0.2433, grad_fn=<SelectBackward>)\n",
      "tensor(0.3465, grad_fn=<SelectBackward>)\n",
      "tensor(0.0262, grad_fn=<SelectBackward>)\n",
      "tensor(0.3092, grad_fn=<SelectBackward>)\n",
      "tensor(0.5002, grad_fn=<SelectBackward>)\n",
      "tensor(0.1492, grad_fn=<SelectBackward>)\n",
      "tensor(0.8677, grad_fn=<SelectBackward>)\n",
      "tensor(0.6168, grad_fn=<SelectBackward>)\n",
      "tensor(0.5197, grad_fn=<SelectBackward>)\n",
      "tensor(1.1512, grad_fn=<SelectBackward>)\n",
      "tensor(0.5119, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0108, grad_fn=<SelectBackward>)\n",
      "tensor(0.3488, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1006, grad_fn=<SelectBackward>)\n",
      "tensor(1.0030, grad_fn=<SelectBackward>)\n",
      "tensor(0.1475, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1260, grad_fn=<SelectBackward>)\n",
      "tensor(0.4058, grad_fn=<SelectBackward>)\n",
      "tensor(0.9393, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0509, grad_fn=<SelectBackward>)\n",
      "tensor(0.1812, grad_fn=<SelectBackward>)\n",
      "tensor(0.1457, grad_fn=<SelectBackward>)\n",
      "tensor(0.9846, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0065, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1477, grad_fn=<SelectBackward>)\n",
      "tensor(0.5448, grad_fn=<SelectBackward>)\n",
      "tensor(0.2197, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0952, grad_fn=<SelectBackward>)\n",
      "tensor(0.0750, grad_fn=<SelectBackward>)\n",
      "tensor(0.9459, grad_fn=<SelectBackward>)\n",
      "tensor(0.5309, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0054, grad_fn=<SelectBackward>)\n",
      "tensor(0.9896, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0435, grad_fn=<SelectBackward>)\n",
      "tensor(0.0876, grad_fn=<SelectBackward>)\n",
      "tensor(0.0834, grad_fn=<SelectBackward>)\n",
      "tensor(0.5042, grad_fn=<SelectBackward>)\n",
      "tensor(0.2482, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1652, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0228, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0553, grad_fn=<SelectBackward>)\n",
      "tensor(0.7669, grad_fn=<SelectBackward>)\n",
      "tensor(0.1375, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0457, grad_fn=<SelectBackward>)\n",
      "tensor(0.7184, grad_fn=<SelectBackward>)\n",
      "tensor(0.0517, grad_fn=<SelectBackward>)\n",
      "tensor(0.0051, grad_fn=<SelectBackward>)\n",
      "tensor(0.1158, grad_fn=<SelectBackward>)\n",
      "tensor(0.9276, grad_fn=<SelectBackward>)\n",
      "tensor(0.1758, grad_fn=<SelectBackward>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward>)\n",
      "tensor(0.7122, grad_fn=<SelectBackward>)\n",
      "tensor(0.1878, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0323, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0489, grad_fn=<SelectBackward>)\n",
      "tensor(0.0506, grad_fn=<SelectBackward>)\n",
      "tensor(0.1244, grad_fn=<SelectBackward>)\n",
      "tensor(0.2662, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0986, grad_fn=<SelectBackward>)\n",
      "tensor(0.2263, grad_fn=<SelectBackward>)\n",
      "tensor(0.7626, grad_fn=<SelectBackward>)\n",
      "tensor(0.0769, grad_fn=<SelectBackward>)\n",
      "tensor(0.8890, grad_fn=<SelectBackward>)\n",
      "tensor(0.6805, grad_fn=<SelectBackward>)\n",
      "tensor(0.4718, grad_fn=<SelectBackward>)\n",
      "tensor(0.1687, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6955, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0044, grad_fn=<SelectBackward>)\n",
      "tensor(0.7613, grad_fn=<SelectBackward>)\n",
      "tensor(0.4091, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0391, grad_fn=<SelectBackward>)\n",
      "tensor(0.2319, grad_fn=<SelectBackward>)\n",
      "tensor(0.0918, grad_fn=<SelectBackward>)\n",
      "tensor(0.1801, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1436, grad_fn=<SelectBackward>)\n",
      "tensor(0.4814, grad_fn=<SelectBackward>)\n",
      "tensor(0.2450, grad_fn=<SelectBackward>)\n",
      "tensor(0.4692, grad_fn=<SelectBackward>)\n",
      "tensor(0.5669, grad_fn=<SelectBackward>)\n",
      "tensor(0.1723, grad_fn=<SelectBackward>)\n",
      "tensor(0.6637, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1816, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0585, grad_fn=<SelectBackward>)\n",
      "tensor(0.7714, grad_fn=<SelectBackward>)\n",
      "tensor(0.3158, grad_fn=<SelectBackward>)\n",
      "tensor(0.9632, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0359, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0030, grad_fn=<SelectBackward>)\n",
      "tensor(1.0382, grad_fn=<SelectBackward>)\n",
      "tensor(0.1410, grad_fn=<SelectBackward>)\n",
      "tensor(0.1203, grad_fn=<SelectBackward>)\n",
      "tensor(0.4512, grad_fn=<SelectBackward>)\n",
      "tensor(0.1928, grad_fn=<SelectBackward>)\n",
      "tensor(0.1132, grad_fn=<SelectBackward>)\n",
      "tensor(0.2852, grad_fn=<SelectBackward>)\n",
      "tensor(0.1695, grad_fn=<SelectBackward>)\n",
      "tensor(0.1768, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1186, grad_fn=<SelectBackward>)\n",
      "tensor(0.4759, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0611, grad_fn=<SelectBackward>)\n",
      "tensor(0.4729, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1725, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1948, grad_fn=<SelectBackward>)\n",
      "tensor(0.2411, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0510, grad_fn=<SelectBackward>)\n",
      "tensor(0.0250, grad_fn=<SelectBackward>)\n",
      "tensor(0.2517, grad_fn=<SelectBackward>)\n",
      "tensor(0.0231, grad_fn=<SelectBackward>)\n",
      "tensor(0.3811, grad_fn=<SelectBackward>)\n",
      "tensor(0.0544, grad_fn=<SelectBackward>)\n",
      "tensor(0.2546, grad_fn=<SelectBackward>)\n",
      "tensor(0.2305, grad_fn=<SelectBackward>)\n",
      "tensor(0.3365, grad_fn=<SelectBackward>)\n",
      "tensor(0.0877, grad_fn=<SelectBackward>)\n",
      "tensor(0.0324, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1595, grad_fn=<SelectBackward>)\n",
      "tensor(0.1985, grad_fn=<SelectBackward>)\n",
      "tensor(0.2261, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0262, grad_fn=<SelectBackward>)\n",
      "tensor(0.3770, grad_fn=<SelectBackward>)\n",
      "tensor(0.3885, grad_fn=<SelectBackward>)\n",
      "tensor(0.2379, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0626, grad_fn=<SelectBackward>)\n",
      "tensor(0.1265, grad_fn=<SelectBackward>)\n",
      "tensor(0.2411, grad_fn=<SelectBackward>)\n",
      "tensor(0.5141, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0326, grad_fn=<SelectBackward>)\n",
      "tensor(0.5642, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1155, grad_fn=<SelectBackward>)\n",
      "tensor(0.0433, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1338, grad_fn=<SelectBackward>)\n",
      "tensor(0.9114, grad_fn=<SelectBackward>)\n",
      "tensor(0.6178, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0956, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0340, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0225, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0318, grad_fn=<SelectBackward>)\n",
      "tensor(0.3086, grad_fn=<SelectBackward>)\n",
      "tensor(0.4290, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0438, grad_fn=<SelectBackward>)\n",
      "tensor(0.0107, grad_fn=<SelectBackward>)\n",
      "tensor(0.7071, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0169, grad_fn=<SelectBackward>)\n",
      "tensor(0.4690, grad_fn=<SelectBackward>)\n",
      "tensor(0.1877, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0349, grad_fn=<SelectBackward>)\n",
      "tensor(0.1277, grad_fn=<SelectBackward>)\n",
      "tensor(0.4238, grad_fn=<SelectBackward>)\n",
      "tensor(0.4349, grad_fn=<SelectBackward>)\n",
      "tensor(0.2202, grad_fn=<SelectBackward>)\n",
      "tensor(0.0867, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0604, grad_fn=<SelectBackward>)\n",
      "tensor(0.1648, grad_fn=<SelectBackward>)\n",
      "tensor(0.1279, grad_fn=<SelectBackward>)\n",
      "tensor(0.6589, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1100, grad_fn=<SelectBackward>)\n",
      "tensor(0.0249, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2005, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0597, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0518, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0254, grad_fn=<SelectBackward>)\n",
      "tensor(1.0170, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0432, grad_fn=<SelectBackward>)\n",
      "tensor(1.0529, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0036, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0178, grad_fn=<SelectBackward>)\n",
      "tensor(0.9277, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1317, grad_fn=<SelectBackward>)\n",
      "tensor(0.0170, grad_fn=<SelectBackward>)\n",
      "tensor(0.0318, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1145, grad_fn=<SelectBackward>)\n",
      "tensor(0.2691, grad_fn=<SelectBackward>)\n",
      "tensor(0.1783, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2173, grad_fn=<SelectBackward>)\n",
      "tensor(0.1217, grad_fn=<SelectBackward>)\n",
      "tensor(0.2696, grad_fn=<SelectBackward>)\n",
      "tensor(0.2818, grad_fn=<SelectBackward>)\n",
      "tensor(0.0467, grad_fn=<SelectBackward>)\n",
      "tensor(0.3171, grad_fn=<SelectBackward>)\n",
      "tensor(0.3301, grad_fn=<SelectBackward>)\n",
      "tensor(0.3876, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0313, grad_fn=<SelectBackward>)\n",
      "tensor(0.2282, grad_fn=<SelectBackward>)\n",
      "tensor(0.7091, grad_fn=<SelectBackward>)\n",
      "tensor(0.0692, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2294, grad_fn=<SelectBackward>)\n",
      "tensor(0.0931, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1610, grad_fn=<SelectBackward>)\n",
      "tensor(0.4450, grad_fn=<SelectBackward>)\n",
      "tensor(0.1978, grad_fn=<SelectBackward>)\n",
      "tensor(0.4688, grad_fn=<SelectBackward>)\n",
      "tensor(0.0334, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0146, grad_fn=<SelectBackward>)\n",
      "tensor(0.2608, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2320, grad_fn=<SelectBackward>)\n",
      "tensor(0.0321, grad_fn=<SelectBackward>)\n",
      "tensor(0.2096, grad_fn=<SelectBackward>)\n",
      "tensor(0.0065, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0429, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0063, grad_fn=<SelectBackward>)\n",
      "tensor(0.3318, grad_fn=<SelectBackward>)\n",
      "tensor(0.0249, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0517, grad_fn=<SelectBackward>)\n",
      "tensor(0.1901, grad_fn=<SelectBackward>)\n",
      "tensor(0.2592, grad_fn=<SelectBackward>)\n",
      "tensor(0.4659, grad_fn=<SelectBackward>)\n",
      "tensor(0.5188, grad_fn=<SelectBackward>)\n",
      "tensor(0.0569, grad_fn=<SelectBackward>)\n",
      "tensor(0.0065, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0114, grad_fn=<SelectBackward>)\n",
      "tensor(0.3673, grad_fn=<SelectBackward>)\n",
      "tensor(0.3598, grad_fn=<SelectBackward>)\n",
      "tensor(0.7380, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1408, grad_fn=<SelectBackward>)\n",
      "tensor(0.2214, grad_fn=<SelectBackward>)\n",
      "tensor(0.0213, grad_fn=<SelectBackward>)\n",
      "tensor(0.0992, grad_fn=<SelectBackward>)\n",
      "tensor(0.5141, grad_fn=<SelectBackward>)\n",
      "tensor(0.8297, grad_fn=<SelectBackward>)\n",
      "tensor(0.0323, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1545, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0239, grad_fn=<SelectBackward>)\n",
      "tensor(0.3895, grad_fn=<SelectBackward>)\n",
      "tensor(0.5308, grad_fn=<SelectBackward>)\n",
      "tensor(0.0015, grad_fn=<SelectBackward>)\n",
      "tensor(0.1815, grad_fn=<SelectBackward>)\n",
      "tensor(0.1397, grad_fn=<SelectBackward>)\n",
      "tensor(1.0445, grad_fn=<SelectBackward>)\n",
      "tensor(0.1806, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0470, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1586, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0141, grad_fn=<SelectBackward>)\n",
      "tensor(0.3075, grad_fn=<SelectBackward>)\n",
      "tensor(0.2651, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1051, grad_fn=<SelectBackward>)\n",
      "tensor(0.1004, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0584, grad_fn=<SelectBackward>)\n",
      "tensor(0.1865, grad_fn=<SelectBackward>)\n",
      "tensor(0.3549, grad_fn=<SelectBackward>)\n",
      "tensor(0.9781, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1270, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0319, grad_fn=<SelectBackward>)\n",
      "tensor(0.1363, grad_fn=<SelectBackward>)\n",
      "tensor(0.1954, grad_fn=<SelectBackward>)\n",
      "tensor(0.4499, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0981, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1609, grad_fn=<SelectBackward>)\n",
      "tensor(0.3868, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0120, grad_fn=<SelectBackward>)\n",
      "tensor(0.7698, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1091, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0113, grad_fn=<SelectBackward>)\n",
      "tensor(0.6049, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0696, grad_fn=<SelectBackward>)\n",
      "tensor(0.2515, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1536, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0280, grad_fn=<SelectBackward>)\n",
      "tensor(0.0802, grad_fn=<SelectBackward>)\n",
      "tensor(0.0829, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1184, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1815, grad_fn=<SelectBackward>)\n",
      "tensor(0.6657, grad_fn=<SelectBackward>)\n",
      "tensor(0.9425, grad_fn=<SelectBackward>)\n",
      "tensor(0.3241, grad_fn=<SelectBackward>)\n",
      "tensor(0.1463, grad_fn=<SelectBackward>)\n",
      "tensor(0.1346, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0562, grad_fn=<SelectBackward>)\n",
      "tensor(0.0592, grad_fn=<SelectBackward>)\n",
      "tensor(0.1020, grad_fn=<SelectBackward>)\n",
      "tensor(0.2989, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0847, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0062, grad_fn=<SelectBackward>)\n",
      "tensor(0.0396, grad_fn=<SelectBackward>)\n",
      "tensor(0.4869, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0110, grad_fn=<SelectBackward>)\n",
      "tensor(0.6038, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0661, grad_fn=<SelectBackward>)\n",
      "tensor(0.3809, grad_fn=<SelectBackward>)\n",
      "tensor(0.5282, grad_fn=<SelectBackward>)\n",
      "tensor(0.0744, grad_fn=<SelectBackward>)\n",
      "tensor(0.0613, grad_fn=<SelectBackward>)\n",
      "tensor(0.0093, grad_fn=<SelectBackward>)\n",
      "tensor(0.1156, grad_fn=<SelectBackward>)\n",
      "tensor(0.4877, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0437, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0336, grad_fn=<SelectBackward>)\n",
      "tensor(0.2703, grad_fn=<SelectBackward>)\n",
      "tensor(0.0517, grad_fn=<SelectBackward>)\n",
      "tensor(0.5346, grad_fn=<SelectBackward>)\n",
      "tensor(0.1119, grad_fn=<SelectBackward>)\n",
      "tensor(0.2841, grad_fn=<SelectBackward>)\n",
      "tensor(0.1975, grad_fn=<SelectBackward>)\n",
      "tensor(0.0471, grad_fn=<SelectBackward>)\n",
      "tensor(0.5815, grad_fn=<SelectBackward>)\n",
      "tensor(0.1812, grad_fn=<SelectBackward>)\n",
      "tensor(0.0699, grad_fn=<SelectBackward>)\n",
      "tensor(0.1307, grad_fn=<SelectBackward>)\n",
      "tensor(0.2164, grad_fn=<SelectBackward>)\n",
      "tensor(0.3663, grad_fn=<SelectBackward>)\n",
      "tensor(0.2964, grad_fn=<SelectBackward>)\n",
      "tensor(0.2552, grad_fn=<SelectBackward>)\n",
      "tensor(0.4809, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward>)\n",
      "tensor(0.1353, grad_fn=<SelectBackward>)\n",
      "tensor(0.0980, grad_fn=<SelectBackward>)\n",
      "tensor(0.1836, grad_fn=<SelectBackward>)\n",
      "tensor(0.2691, grad_fn=<SelectBackward>)\n",
      "tensor(0.1981, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0528, grad_fn=<SelectBackward>)\n",
      "tensor(0.2289, grad_fn=<SelectBackward>)\n",
      "tensor(0.0181, grad_fn=<SelectBackward>)\n",
      "tensor(0.2578, grad_fn=<SelectBackward>)\n",
      "tensor(0.2852, grad_fn=<SelectBackward>)\n",
      "tensor(0.0794, grad_fn=<SelectBackward>)\n",
      "tensor(0.4538, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0580, grad_fn=<SelectBackward>)\n",
      "tensor(1.0683, grad_fn=<SelectBackward>)\n",
      "tensor(0.0493, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1401, grad_fn=<SelectBackward>)\n",
      "tensor(0.2213, grad_fn=<SelectBackward>)\n",
      "tensor(0.0885, grad_fn=<SelectBackward>)\n",
      "tensor(0.6726, grad_fn=<SelectBackward>)\n",
      "tensor(0.3163, grad_fn=<SelectBackward>)\n",
      "tensor(0.1694, grad_fn=<SelectBackward>)\n",
      "tensor(0.0511, grad_fn=<SelectBackward>)\n",
      "tensor(0.9610, grad_fn=<SelectBackward>)\n",
      "tensor(0.0809, grad_fn=<SelectBackward>)\n",
      "tensor(0.4205, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0172, grad_fn=<SelectBackward>)\n",
      "tensor(1.0143, grad_fn=<SelectBackward>)\n",
      "tensor(0.3515, grad_fn=<SelectBackward>)\n",
      "tensor(0.0553, grad_fn=<SelectBackward>)\n",
      "tensor(0.2272, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0351, grad_fn=<SelectBackward>)\n",
      "tensor(0.0942, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0193, grad_fn=<SelectBackward>)\n",
      "tensor(0.1819, grad_fn=<SelectBackward>)\n",
      "tensor(0.2485, grad_fn=<SelectBackward>)\n",
      "tensor(0.0726, grad_fn=<SelectBackward>)\n",
      "tensor(0.4631, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1004, grad_fn=<SelectBackward>)\n",
      "tensor(0.1608, grad_fn=<SelectBackward>)\n",
      "tensor(0.4979, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0192, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0561, grad_fn=<SelectBackward>)\n",
      "tensor(0.0187, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0910, grad_fn=<SelectBackward>)\n",
      "tensor(0.2613, grad_fn=<SelectBackward>)\n",
      "tensor(0.3766, grad_fn=<SelectBackward>)\n",
      "tensor(0.3872, grad_fn=<SelectBackward>)\n",
      "tensor(0.2746, grad_fn=<SelectBackward>)\n",
      "tensor(0.1229, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0183, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0462, grad_fn=<SelectBackward>)\n",
      "tensor(0.0276, grad_fn=<SelectBackward>)\n",
      "tensor(0.0260, grad_fn=<SelectBackward>)\n",
      "tensor(0.0969, grad_fn=<SelectBackward>)\n",
      "tensor(0.1431, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0648, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0538, grad_fn=<SelectBackward>)\n",
      "tensor(0.1212, grad_fn=<SelectBackward>)\n",
      "tensor(0.0654, grad_fn=<SelectBackward>)\n",
      "tensor(0.2527, grad_fn=<SelectBackward>)\n",
      "tensor(0.3527, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0025, grad_fn=<SelectBackward>)\n",
      "tensor(0.0227, grad_fn=<SelectBackward>)\n",
      "tensor(0.2078, grad_fn=<SelectBackward>)\n",
      "tensor(0.0818, grad_fn=<SelectBackward>)\n",
      "tensor(0.8087, grad_fn=<SelectBackward>)\n",
      "tensor(0.0958, grad_fn=<SelectBackward>)\n",
      "tensor(0.1415, grad_fn=<SelectBackward>)\n",
      "tensor(0.1968, grad_fn=<SelectBackward>)\n",
      "tensor(0.4163, grad_fn=<SelectBackward>)\n",
      "tensor(0.1628, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1058, grad_fn=<SelectBackward>)\n",
      "tensor(0.6788, grad_fn=<SelectBackward>)\n",
      "tensor(0.7836, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0459, grad_fn=<SelectBackward>)\n",
      "tensor(0.9482, grad_fn=<SelectBackward>)\n",
      "tensor(0.0065, grad_fn=<SelectBackward>)\n",
      "tensor(0.0644, grad_fn=<SelectBackward>)\n",
      "tensor(0.2770, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0141, grad_fn=<SelectBackward>)\n",
      "tensor(0.0517, grad_fn=<SelectBackward>)\n",
      "tensor(0.4160, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0540, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1187, grad_fn=<SelectBackward>)\n",
      "tensor(1.0285, grad_fn=<SelectBackward>)\n",
      "tensor(0.1627, grad_fn=<SelectBackward>)\n",
      "tensor(0.3504, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0386, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1348, grad_fn=<SelectBackward>)\n",
      "tensor(0.3480, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0199, grad_fn=<SelectBackward>)\n",
      "tensor(0.5796, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0476, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2219, grad_fn=<SelectBackward>)\n",
      "tensor(1.0720, grad_fn=<SelectBackward>)\n",
      "tensor(0.1006, grad_fn=<SelectBackward>)\n",
      "tensor(0.3919, grad_fn=<SelectBackward>)\n",
      "tensor(0.2674, grad_fn=<SelectBackward>)\n",
      "tensor(0.1282, grad_fn=<SelectBackward>)\n",
      "tensor(0.2507, grad_fn=<SelectBackward>)\n",
      "tensor(0.3904, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1453, grad_fn=<SelectBackward>)\n",
      "tensor(0.0553, grad_fn=<SelectBackward>)\n",
      "tensor(0.3170, grad_fn=<SelectBackward>)\n",
      "tensor(0.2155, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0538, grad_fn=<SelectBackward>)\n",
      "tensor(0.2136, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1950, grad_fn=<SelectBackward>)\n",
      "tensor(0.1754, grad_fn=<SelectBackward>)\n",
      "tensor(0.5276, grad_fn=<SelectBackward>)\n",
      "tensor(0.0535, grad_fn=<SelectBackward>)\n",
      "tensor(0.1158, grad_fn=<SelectBackward>)\n",
      "tensor(0.2466, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0109, grad_fn=<SelectBackward>)\n",
      "tensor(0.7998, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1605, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0265, grad_fn=<SelectBackward>)\n",
      "tensor(0.1904, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1000, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0235, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0256, grad_fn=<SelectBackward>)\n",
      "tensor(0.0523, grad_fn=<SelectBackward>)\n",
      "tensor(0.2630, grad_fn=<SelectBackward>)\n",
      "tensor(0.6072, grad_fn=<SelectBackward>)\n",
      "tensor(0.5230, grad_fn=<SelectBackward>)\n",
      "tensor(0.3073, grad_fn=<SelectBackward>)\n",
      "tensor(0.3796, grad_fn=<SelectBackward>)\n",
      "tensor(0.7013, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0809, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0374, grad_fn=<SelectBackward>)\n",
      "tensor(0.1505, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0558, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1858, grad_fn=<SelectBackward>)\n",
      "tensor(0.0316, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0353, grad_fn=<SelectBackward>)\n",
      "tensor(0.1808, grad_fn=<SelectBackward>)\n",
      "tensor(0.8053, grad_fn=<SelectBackward>)\n",
      "tensor(0.0377, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0226, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0453, grad_fn=<SelectBackward>)\n",
      "tensor(0.0552, grad_fn=<SelectBackward>)\n",
      "tensor(0.0401, grad_fn=<SelectBackward>)\n",
      "tensor(0.2762, grad_fn=<SelectBackward>)\n",
      "tensor(0.0186, grad_fn=<SelectBackward>)\n",
      "tensor(0.2029, grad_fn=<SelectBackward>)\n",
      "tensor(0.2556, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0030, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0459, grad_fn=<SelectBackward>)\n",
      "tensor(0.3124, grad_fn=<SelectBackward>)\n",
      "tensor(0.2243, grad_fn=<SelectBackward>)\n",
      "tensor(0.5588, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0097, grad_fn=<SelectBackward>)\n",
      "tensor(0.1296, grad_fn=<SelectBackward>)\n",
      "tensor(0.0172, grad_fn=<SelectBackward>)\n",
      "tensor(0.1681, grad_fn=<SelectBackward>)\n",
      "tensor(0.2424, grad_fn=<SelectBackward>)\n",
      "tensor(0.6063, grad_fn=<SelectBackward>)\n",
      "tensor(0.1493, grad_fn=<SelectBackward>)\n",
      "tensor(0.3794, grad_fn=<SelectBackward>)\n",
      "tensor(0.0364, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2333, grad_fn=<SelectBackward>)\n",
      "tensor(0.4062, grad_fn=<SelectBackward>)\n",
      "tensor(0.3234, grad_fn=<SelectBackward>)\n",
      "tensor(0.5449, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0763, grad_fn=<SelectBackward>)\n",
      "tensor(0.2886, grad_fn=<SelectBackward>)\n",
      "tensor(0.2801, grad_fn=<SelectBackward>)\n",
      "tensor(0.6173, grad_fn=<SelectBackward>)\n",
      "tensor(0.4009, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0895, grad_fn=<SelectBackward>)\n",
      "tensor(0.9603, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0315, grad_fn=<SelectBackward>)\n",
      "tensor(0.0052, grad_fn=<SelectBackward>)\n",
      "tensor(0.2467, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0143, grad_fn=<SelectBackward>)\n",
      "tensor(0.1539, grad_fn=<SelectBackward>)\n",
      "tensor(0.2131, grad_fn=<SelectBackward>)\n",
      "tensor(0.7292, grad_fn=<SelectBackward>)\n",
      "tensor(0.4320, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1063, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0431, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5233, grad_fn=<SelectBackward>)\n",
      "tensor(0.3694, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1115, grad_fn=<SelectBackward>)\n",
      "tensor(0.1522, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0349, grad_fn=<SelectBackward>)\n",
      "tensor(0.5356, grad_fn=<SelectBackward>)\n",
      "tensor(1.1063, grad_fn=<SelectBackward>)\n",
      "tensor(0.3172, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0590, grad_fn=<SelectBackward>)\n",
      "tensor(0.1174, grad_fn=<SelectBackward>)\n",
      "tensor(0.4870, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0983, grad_fn=<SelectBackward>)\n",
      "tensor(0.4475, grad_fn=<SelectBackward>)\n",
      "tensor(0.0062, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1703, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1193, grad_fn=<SelectBackward>)\n",
      "tensor(0.8866, grad_fn=<SelectBackward>)\n",
      "tensor(0.9684, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0301, grad_fn=<SelectBackward>)\n",
      "tensor(0.2532, grad_fn=<SelectBackward>)\n",
      "tensor(0.4597, grad_fn=<SelectBackward>)\n",
      "tensor(0.0573, grad_fn=<SelectBackward>)\n",
      "tensor(0.7878, grad_fn=<SelectBackward>)\n",
      "tensor(0.3114, grad_fn=<SelectBackward>)\n",
      "tensor(0.2153, grad_fn=<SelectBackward>)\n",
      "tensor(0.2993, grad_fn=<SelectBackward>)\n",
      "tensor(0.2278, grad_fn=<SelectBackward>)\n",
      "tensor(0.0546, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0452, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0783, grad_fn=<SelectBackward>)\n",
      "tensor(0.1837, grad_fn=<SelectBackward>)\n",
      "tensor(0.3034, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0177, grad_fn=<SelectBackward>)\n",
      "tensor(0.1598, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0501, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0468, grad_fn=<SelectBackward>)\n",
      "tensor(0.0712, grad_fn=<SelectBackward>)\n",
      "tensor(0.1104, grad_fn=<SelectBackward>)\n",
      "tensor(0.0790, grad_fn=<SelectBackward>)\n",
      "tensor(0.3142, grad_fn=<SelectBackward>)\n",
      "tensor(0.2562, grad_fn=<SelectBackward>)\n",
      "tensor(0.1283, grad_fn=<SelectBackward>)\n",
      "tensor(0.0191, grad_fn=<SelectBackward>)\n",
      "tensor(0.7819, grad_fn=<SelectBackward>)\n",
      "tensor(0.8316, grad_fn=<SelectBackward>)\n",
      "tensor(0.1356, grad_fn=<SelectBackward>)\n",
      "tensor(0.0735, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0541, grad_fn=<SelectBackward>)\n",
      "tensor(1.0655, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0895, grad_fn=<SelectBackward>)\n",
      "tensor(0.0649, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0221, grad_fn=<SelectBackward>)\n",
      "tensor(0.0063, grad_fn=<SelectBackward>)\n",
      "tensor(0.1540, grad_fn=<SelectBackward>)\n",
      "tensor(0.4069, grad_fn=<SelectBackward>)\n",
      "tensor(0.2686, grad_fn=<SelectBackward>)\n",
      "tensor(0.0330, grad_fn=<SelectBackward>)\n",
      "tensor(0.1291, grad_fn=<SelectBackward>)\n",
      "tensor(0.0633, grad_fn=<SelectBackward>)\n",
      "tensor(0.0099, grad_fn=<SelectBackward>)\n",
      "tensor(0.0895, grad_fn=<SelectBackward>)\n",
      "tensor(0.1515, grad_fn=<SelectBackward>)\n",
      "tensor(0.0745, grad_fn=<SelectBackward>)\n",
      "tensor(0.0030, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1142, grad_fn=<SelectBackward>)\n",
      "tensor(0.2280, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0327, grad_fn=<SelectBackward>)\n",
      "tensor(0.3051, grad_fn=<SelectBackward>)\n",
      "tensor(0.8515, grad_fn=<SelectBackward>)\n",
      "tensor(0.1245, grad_fn=<SelectBackward>)\n",
      "tensor(0.1740, grad_fn=<SelectBackward>)\n",
      "tensor(0.0975, grad_fn=<SelectBackward>)\n",
      "tensor(0.0134, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0411, grad_fn=<SelectBackward>)\n",
      "tensor(0.3477, grad_fn=<SelectBackward>)\n",
      "tensor(0.3125, grad_fn=<SelectBackward>)\n",
      "tensor(0.3195, grad_fn=<SelectBackward>)\n",
      "tensor(0.8387, grad_fn=<SelectBackward>)\n",
      "tensor(0.3244, grad_fn=<SelectBackward>)\n",
      "tensor(0.1724, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1449, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0160, grad_fn=<SelectBackward>)\n",
      "tensor(0.4743, grad_fn=<SelectBackward>)\n",
      "tensor(0.3730, grad_fn=<SelectBackward>)\n",
      "tensor(0.1914, grad_fn=<SelectBackward>)\n",
      "tensor(0.1944, grad_fn=<SelectBackward>)\n",
      "tensor(0.2937, grad_fn=<SelectBackward>)\n",
      "tensor(0.1407, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1679, grad_fn=<SelectBackward>)\n",
      "tensor(0.2779, grad_fn=<SelectBackward>)\n",
      "tensor(0.3540, grad_fn=<SelectBackward>)\n",
      "tensor(0.6032, grad_fn=<SelectBackward>)\n",
      "tensor(0.8095, grad_fn=<SelectBackward>)\n",
      "tensor(0.7998, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0994, grad_fn=<SelectBackward>)\n",
      "tensor(0.1242, grad_fn=<SelectBackward>)\n",
      "tensor(0.0556, grad_fn=<SelectBackward>)\n",
      "tensor(0.1988, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1106, grad_fn=<SelectBackward>)\n",
      "tensor(0.2119, grad_fn=<SelectBackward>)\n",
      "tensor(0.1338, grad_fn=<SelectBackward>)\n",
      "tensor(0.0868, grad_fn=<SelectBackward>)\n",
      "tensor(0.4335, grad_fn=<SelectBackward>)\n",
      "tensor(0.7788, grad_fn=<SelectBackward>)\n",
      "tensor(0.2431, grad_fn=<SelectBackward>)\n",
      "tensor(0.1490, grad_fn=<SelectBackward>)\n",
      "tensor(0.2726, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0246, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward>)\n",
      "tensor(1.0042, grad_fn=<SelectBackward>)\n",
      "tensor(0.2681, grad_fn=<SelectBackward>)\n",
      "tensor(0.8384, grad_fn=<SelectBackward>)\n",
      "tensor(0.2685, grad_fn=<SelectBackward>)\n",
      "tensor(0.1029, grad_fn=<SelectBackward>)\n",
      "tensor(0.0092, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0995, grad_fn=<SelectBackward>)\n",
      "tensor(0.1792, grad_fn=<SelectBackward>)\n",
      "tensor(0.2898, grad_fn=<SelectBackward>)\n",
      "tensor(0.3158, grad_fn=<SelectBackward>)\n",
      "tensor(0.0149, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0393, grad_fn=<SelectBackward>)\n",
      "tensor(0.1755, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2618, grad_fn=<SelectBackward>)\n",
      "tensor(0.1605, grad_fn=<SelectBackward>)\n",
      "tensor(0.1066, grad_fn=<SelectBackward>)\n",
      "tensor(0.3537, grad_fn=<SelectBackward>)\n",
      "tensor(0.1889, grad_fn=<SelectBackward>)\n",
      "tensor(0.2962, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0181, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0609, grad_fn=<SelectBackward>)\n",
      "tensor(0.6072, grad_fn=<SelectBackward>)\n",
      "tensor(0.3928, grad_fn=<SelectBackward>)\n",
      "tensor(0.1245, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0547, grad_fn=<SelectBackward>)\n",
      "tensor(0.3153, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward>)\n",
      "tensor(0.1233, grad_fn=<SelectBackward>)\n",
      "tensor(0.0809, grad_fn=<SelectBackward>)\n",
      "tensor(0.0200, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1197, grad_fn=<SelectBackward>)\n",
      "tensor(0.0214, grad_fn=<SelectBackward>)\n",
      "tensor(0.0910, grad_fn=<SelectBackward>)\n",
      "tensor(0.1736, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0361, grad_fn=<SelectBackward>)\n",
      "tensor(0.0701, grad_fn=<SelectBackward>)\n",
      "tensor(0.2686, grad_fn=<SelectBackward>)\n",
      "tensor(0.0895, grad_fn=<SelectBackward>)\n",
      "tensor(0.2041, grad_fn=<SelectBackward>)\n",
      "tensor(0.0500, grad_fn=<SelectBackward>)\n",
      "tensor(0.4106, grad_fn=<SelectBackward>)\n",
      "tensor(0.7559, grad_fn=<SelectBackward>)\n",
      "tensor(0.3697, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2501, grad_fn=<SelectBackward>)\n",
      "tensor(0.1411, grad_fn=<SelectBackward>)\n",
      "tensor(0.1359, grad_fn=<SelectBackward>)\n",
      "tensor(0.9280, grad_fn=<SelectBackward>)\n",
      "tensor(0.1308, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0794, grad_fn=<SelectBackward>)\n",
      "tensor(0.1458, grad_fn=<SelectBackward>)\n",
      "tensor(0.2389, grad_fn=<SelectBackward>)\n",
      "tensor(0.7906, grad_fn=<SelectBackward>)\n",
      "tensor(0.1381, grad_fn=<SelectBackward>)\n",
      "tensor(0.3354, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1634, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2281, grad_fn=<SelectBackward>)\n",
      "tensor(0.1768, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0960, grad_fn=<SelectBackward>)\n",
      "tensor(0.2561, grad_fn=<SelectBackward>)\n",
      "tensor(0.7566, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0110, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1188, grad_fn=<SelectBackward>)\n",
      "tensor(0.0959, grad_fn=<SelectBackward>)\n",
      "tensor(0.7327, grad_fn=<SelectBackward>)\n",
      "tensor(0.7759, grad_fn=<SelectBackward>)\n",
      "tensor(0.6908, grad_fn=<SelectBackward>)\n",
      "tensor(0.1518, grad_fn=<SelectBackward>)\n",
      "tensor(0.1577, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1124, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1653, grad_fn=<SelectBackward>)\n",
      "tensor(0.1158, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2083, grad_fn=<SelectBackward>)\n",
      "tensor(1.1841, grad_fn=<SelectBackward>)\n",
      "tensor(0.5499, grad_fn=<SelectBackward>)\n",
      "tensor(0.1968, grad_fn=<SelectBackward>)\n",
      "tensor(0.0489, grad_fn=<SelectBackward>)\n",
      "tensor(0.1299, grad_fn=<SelectBackward>)\n",
      "tensor(0.0645, grad_fn=<SelectBackward>)\n",
      "tensor(0.2753, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0042, grad_fn=<SelectBackward>)\n",
      "tensor(0.2412, grad_fn=<SelectBackward>)\n",
      "tensor(0.5471, grad_fn=<SelectBackward>)\n",
      "tensor(0.1412, grad_fn=<SelectBackward>)\n",
      "tensor(0.0017, grad_fn=<SelectBackward>)\n",
      "tensor(0.7248, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0869, grad_fn=<SelectBackward>)\n",
      "tensor(0.3261, grad_fn=<SelectBackward>)\n",
      "tensor(0.1173, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1609, grad_fn=<SelectBackward>)\n",
      "tensor(0.0763, grad_fn=<SelectBackward>)\n",
      "tensor(0.9313, grad_fn=<SelectBackward>)\n",
      "tensor(0.3671, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0736, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2537, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6535, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0022, grad_fn=<SelectBackward>)\n",
      "tensor(0.0918, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1613, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0134, grad_fn=<SelectBackward>)\n",
      "tensor(0.4021, grad_fn=<SelectBackward>)\n",
      "tensor(0.1656, grad_fn=<SelectBackward>)\n",
      "tensor(0.0400, grad_fn=<SelectBackward>)\n",
      "tensor(0.2498, grad_fn=<SelectBackward>)\n",
      "tensor(0.4882, grad_fn=<SelectBackward>)\n",
      "tensor(-0.0865, grad_fn=<SelectBackward>)\n",
      "tensor(1.3157, grad_fn=<SelectBackward>)\n",
      "tensor(0.2027, grad_fn=<SelectBackward>)\n",
      "tensor(0.2471, grad_fn=<SelectBackward>)\n",
      "tensor(0.7405, grad_fn=<SelectBackward>)\n",
      "tensor(0.8623, grad_fn=<SelectBackward>)\n",
      "tensor(0.6010, grad_fn=<SelectBackward>)\n",
      "tensor(0.3471, grad_fn=<SelectBackward>)\n",
      "tensor(0.0297, grad_fn=<SelectBackward>)\n",
      "tensor(0.3780, grad_fn=<SelectBackward>)\n",
      "tensor(0.3214, grad_fn=<SelectBackward>)\n",
      "tensor(0.5090, grad_fn=<SelectBackward>)\n",
      "tensor(0.0369, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1025, grad_fn=<SelectBackward>)\n",
      "tensor(0.2558, grad_fn=<SelectBackward>)\n",
      "tensor(0.2195, grad_fn=<SelectBackward>)\n",
      "tensor(0.0082, grad_fn=<SelectBackward>)\n",
      "tensor(0.3102, grad_fn=<SelectBackward>)\n",
      "tensor(0.8620, grad_fn=<SelectBackward>)\n",
      "tensor(0.4325, grad_fn=<SelectBackward>)\n",
      "tensor(0.3962, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1313, grad_fn=<SelectBackward>)\n",
      "tensor(0.1887, grad_fn=<SelectBackward>)\n",
      "tensor(0.2904, grad_fn=<SelectBackward>)\n",
      "tensor(0.0147, grad_fn=<SelectBackward>)\n",
      "tensor(1.1082, grad_fn=<SelectBackward>)\n",
      "tensor(0.4100, grad_fn=<SelectBackward>)\n",
      "tensor(0.0250, grad_fn=<SelectBackward>)\n",
      "tensor(0.1901, grad_fn=<SelectBackward>)\n",
      "tensor(0.3704, grad_fn=<SelectBackward>)\n",
      "tensor(0.0245, grad_fn=<SelectBackward>)\n",
      "tensor(0.1204, grad_fn=<SelectBackward>)\n",
      "tensor(0.0419, grad_fn=<SelectBackward>)\n",
      "tensor(0.0708, grad_fn=<SelectBackward>)\n",
      "tensor(0.0768, grad_fn=<SelectBackward>)\n",
      "tensor(-0.2725, grad_fn=<SelectBackward>)\n",
      "tensor(0.0545, grad_fn=<SelectBackward>)\n",
      "tensor(0.1774, grad_fn=<SelectBackward>)\n",
      "tensor(0.3240, grad_fn=<SelectBackward>)\n",
      "tensor(-0.1655, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5574085952533675"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(to_tensor(X_val[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = th.randn(3, 5, requires_grad=True)\n",
    "target = th.empty(3, dtype=th.long).random_(5)\n",
    "output = loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -2.9732,   6.9560,   1.0358,   3.4154,  -3.1851,   0.0732,  -0.9837,\n",
       "         -0.1281,   1.8624,  -3.6172,   4.7389,  -5.3215,   5.3464,   0.5851,\n",
       "          2.9931,  -2.0119,   0.3652,  -1.5718,  -2.3623,   4.5758,   2.1746,\n",
       "         -5.7295,   2.4914,   1.3430,  -4.3591,  -3.0535,  -1.7467,  -4.8005,\n",
       "         -3.4430,  -3.9902,   2.1707, -10.8312,  -0.8240,  -3.8727,   1.4123,\n",
       "          3.3897,  -0.0792,   1.5976,   0.9092,  -2.8073],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings(to_tensor(X_train[0])).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    " \n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    " \n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    " \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    " \n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden = self.init_hidden()\n",
    " \n",
    "    def init_hidden(self):\n",
    "        return (autograd.Variable(th.zeros(1, 1, self.hidden_dim)),\n",
    "                autograd.Variable(th.zeros(1, 1, self.hidden_dim)))\n",
    " \n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(-1))\n",
    "        tag_scores = F.log_softmax(tag_space)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class LSTM_classifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(LSTM_classifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
    "        self.linear = nn.Linear(2*hidden_dim, 50)\n",
    "        self.linear2 = nn.Linear(50,1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        out = self.embedding(inputs)\n",
    "        out, (h0,h1) = self.lstm(out.view(len(inputs), 1, -1))\n",
    "        out = F.relu(self.linear(self.dropout(h0.view(-1))))\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "model = LSTM_classifier(num_voc, 100, 100)\n",
    "model.train()\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01,momentum=0.5)\n",
    "model, mean_losss = training_loop(model, optimizer, criterion, EPOCHS, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0003], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(to_tensor(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_classifier(\n",
      "  (embedding): Embedding(13977, 100)\n",
      "  (lstm): LSTM(100, 100, bidirectional=True)\n",
      "  (linear): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (linear2): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Epoch :  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "result type Float can't be cast to the desired output type Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-281755c31f29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# training loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_losss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-156-88ea7bb843a9>\u001b[0m in \u001b[0;36mtraining_loop\u001b[1;34m(model, optimizer, loss_function, n_epochs, datas, labels)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m#dev_accus.append(accuracy)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-156-88ea7bb843a9>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion, data, labels)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# compute the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# compute gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m                                                   reduction=self.reduction)\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   2112\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2114\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: result type Float can't be cast to the desired output type Long"
     ]
    }
   ],
   "source": [
    "# model = LSTMTagger(3,20,num_voc, num_class)\n",
    "# print(model.word_embeddings(to_tensor(X_train[1])))\n",
    "# print(model.word_embeddings(to_tensor(X_train[1])).view(len(X_train[1]), 1, -1))\n",
    "# out, hidden = model.lstm(model.word_embeddings(to_tensor(X_train[1])).view(len(X_train[1]),1,-1),model.hidden)\n",
    "\n",
    "model = LSTM_classifier(num_voc,100,100)\n",
    "#model = CBOW_classifier(num_voc, embedding_dim=EMBED_DIM,)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "print(model)\n",
    "optimizer = th.optim.SGD(model.parameters(),lr=0.01)\n",
    "# training loop\n",
    "model, mean_losss = training_loop(model, optimizer, criterion, EPOCHS, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 200], m2: [20 x 2] at C:\\w\\1\\s\\windows\\pytorch\\aten\\src\\TH/generic/THTensorMath.cpp:197",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-43ac6704d00b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTMTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_voc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-31fb17bb3048>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m     20\u001b[0m         lstm_out, self.hidden = self.lstm(\n\u001b[0;32m     21\u001b[0m             embeds.view(len(sentence), 1, -1), self.hidden)\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mtag_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden2tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mtag_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtag_scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1372\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1373\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 200], m2: [20 x 2] at C:\\w\\1\\s\\windows\\pytorch\\aten\\src\\TH/generic/THTensorMath.cpp:197"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(3,20,num_voc, num_class)\n",
    "model(to_tensor(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, num_output, rnn_model='LSTM', use_last=True, embedding_tensor=None,\n",
    "                 padding_index=0, hidden_size=64, num_layers=1, batch_first=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocab_size: vocab size\n",
    "            embed_size: embedding size\n",
    "            num_output: number of output (classes)\n",
    "            rnn_model:  LSTM or GRU\n",
    "            use_last:  bool\n",
    "            embedding_tensor:\n",
    "            padding_index:\n",
    "            hidden_size: hidden size of rnn module\n",
    "            num_layers:  number of layers in rnn module\n",
    "            batch_first: batch first option\n",
    "        \"\"\"\n",
    "\n",
    "        super(RNN, self).__init__()\n",
    "        self.use_last = use_last\n",
    "        # embedding\n",
    "        self.encoder = None\n",
    "        if torch.is_tensor(embedding_tensor):\n",
    "            self.encoder = nn.Embedding(vocab_size, embed_size, padding_idx=padding_index, _weight=embedding_tensor)\n",
    "            self.encoder.weight.requires_grad = False\n",
    "        else:\n",
    "            self.encoder = nn.Embedding(vocab_size, embed_size, padding_idx=padding_index)\n",
    "\n",
    "        self.drop_en = nn.Dropout(p=0.6)\n",
    "\n",
    "        # rnn module\n",
    "        if rnn_model == 'LSTM':\n",
    "            self.rnn = nn.LSTM( input_size=embed_size, hidden_size=hidden_size, num_layers=num_layers, dropout=0.5,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        elif rnn_model == 'GRU':\n",
    "            self.rnn = nn.GRU( input_size=embed_size, hidden_size=hidden_size, num_layers=num_layers, dropout=0.5,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        else:\n",
    "            raise LookupError(' only support LSTM and GRU')\n",
    "\n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size*2)\n",
    "        self.fc = nn.Linear(hidden_size*2, 1)\n",
    "\n",
    "    def forward(self, x, seq_lengths):\n",
    "        '''\n",
    "        Args:\n",
    "            x: (batch, time_step, input_size)\n",
    "        Returns:\n",
    "            num_output size\n",
    "        '''\n",
    "\n",
    "        x_embed = self.encoder(x)\n",
    "        x_embed = self.drop_en(x_embed)\n",
    "        packed_input = pack_padded_sequence(x_embed, seq_lengths.cpu().numpy(),batch_first=True)\n",
    "\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # None is for initial hidden state\n",
    "        packed_output, ht = self.rnn(packed_input, None)\n",
    "        out_rnn, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        row_indices = torch.arange(0, x.size(0)).long()\n",
    "        col_indices = seq_lengths - 1\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            row_indices = row_indices.cuda()\n",
    "            col_indices = col_indices.cuda()\n",
    "\n",
    "        if self.use_last:\n",
    "            last_tensor=out_rnn[row_indices, col_indices, :]\n",
    "        else:\n",
    "            # use mean\n",
    "            last_tensor = out_rnn[row_indices, :, :]\n",
    "            last_tensor = torch.mean(last_tensor, dim=1)\n",
    "\n",
    "        fc_input = self.bn2(last_tensor)\n",
    "        out = self.fc(fc_input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_x, batch_y):\n",
    "    batch = []\n",
    "    for sentence in batch_x:\n",
    "        batch.append(to_index(sentence))\n",
    "    \n",
    "    sen_lengths = th.tensor(list(map(len, batch)))\n",
    "    \n",
    "    batch_tensor = th.zeros((len(batch), sen_lengths.max())).long()\n",
    "    for idx, (sen, sen_len) in enumerate(zip(batch, sen_lengths)):\n",
    "        batch_tensor[idx, :sen_len] = th.LongTensor(sen)\n",
    "        \n",
    "    sen_lengths, sorted_idx = sen_lengths.sort(0, descending=True)\n",
    "    batch_tensor = batch_tensor[sorted_idx]\n",
    "    \n",
    "    batch_labels = th.tensor(batch_y).view(len(batch_y),-1)\n",
    "    batch_labels = batch_labels[sorted_idx]\n",
    "    \n",
    "    return batch_tensor,batch_labels,sen_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (encoder): Embedding(13977, 40, padding_idx=0)\n",
      "  (drop_en): Dropout(p=0.6, inplace=False)\n",
      "  (rnn): LSTM(40, 64, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "epoch:  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "result type Float can't be cast to the desired output type Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-c09255e8c4f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msen_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# compute the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;31m#total_loss += loss.item()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# compute gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m                                                   reduction=self.reduction)\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   2112\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2114\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: result type Float can't be cast to the desired output type Long"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "model = RNN(num_voc,40,2,num_layers=2)\n",
    "#model = CBOW_classifier(num_voc, embedding_dim=EMBED_DIM,)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "print(model)\n",
    "optimizer = th.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01, weight_decay=0.01)\n",
    "#optimizer = th.optim.SGD(model.parameters(),lr=0.01)\n",
    "for e in range(50):\n",
    "    print('epoch: ', e)\n",
    "    total_loss = 0\n",
    "    for i in range(0,len(X_train),BATCH_SIZE):\n",
    "        batch_tensor,batch_labels,sen_lengths = get_batch(X_train[i:i+BATCH_SIZE], Y_train[i:i+BATCH_SIZE])\n",
    "        optimizer.zero_grad()\n",
    "    #         if to_tensor(x).size()[0] <= WINDOW-1:\n",
    "    #             continue\n",
    "        # output of the model\n",
    "        output = model(batch_tensor,sen_lengths)\n",
    "        # compute the loss\n",
    "        loss = criterion(output, batch_labels)\n",
    "        #total_loss += loss.item()\n",
    "        loss.backward()  # compute gradient\n",
    "        #torch.nn.utils.clip_grad_value_(model.parameters(), 5.)  # clip gradient if its norm exceed 5\n",
    "        optimizer.step()  # update parameters\n",
    "    print('  loss: ',total_loss/len(X_train))\n",
    "    print('  acc : ', eva(model,X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49583066067992304"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva(model,X_val,Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eva(model,x,y):\n",
    "    batch_tensor,batch_labels,sen_lengths = get_batch(x,y)\n",
    "    res = model(batch_tensor,sen_lengths)\n",
    "    return sum(res.argmax(axis=1)==batch_labels).item()/len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (encoder): Embedding(13976, 40, padding_idx=0)\n",
      "  (drop_en): Dropout(p=0.6, inplace=False)\n",
      "  (rnn): LSTM(40, 64, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Epoch :  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 1 elements not 128",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-cfac17be908c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# training loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_losss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-51dd14bbdf58>\u001b[0m in \u001b[0;36mtraining_loop\u001b[1;34m(model, optimizer, loss_function, n_epochs, datas, labels)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m#dev_accus.append(accuracy)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-51dd14bbdf58>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion, data, labels)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m#             continue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# output of the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;31m# compute the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-96a8879cc8c3>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mlast_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_embed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mfc_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfc_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[0;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1670\u001b[1;33m         \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1671\u001b[0m     )\n\u001b[0;32m   1672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: running_mean should contain 1 elements not 128"
     ]
    }
   ],
   "source": [
    "model = RNN(num_voc,40,2)\n",
    "#model = CBOW_classifier(num_voc, embedding_dim=EMBED_DIM,)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)\n",
    "optimizer = th.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01, weight_decay=0.01)\n",
    "# training loop\n",
    "model, mean_losss = training_loop(model, optimizer, criterion, EPOCHS, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
